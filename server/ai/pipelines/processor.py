"""
ë°±ì—”ë“œ A: ìë™í™” íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- STT â†’ PDF ì²˜ë¦¬ â†’ í˜ë¥´ì†Œë‚˜ ì¶”ì¶œ â†’ RAG ì¸ì œìŠ¤íŠ¸
- ìˆœìˆ˜ AI ì²˜ë¦¬ ë¡œì§ë§Œ ë‹´ë‹¹ (DB ì‘ì—… ì œì™¸)
"""
from pathlib import Path
from typing import Optional, List, Dict, Any, Callable

from ai.config import AISettings
from ai.pipelines.rag import RAGPipeline
from ai.services.stt import transcribe_video
from ai.style_analyzer import analyze_instructor_style
import json
import hashlib


def process_course_assets(
    *,
    course_id: str,
    instructor_id: str,
    video_path: Optional[Path] = None,
    audio_path: Optional[Path] = None,
    pdf_path: Optional[Path] = None,
    smi_path: Optional[Path] = None,
    update_progress: Optional[Callable[[int, str], None]] = None,
    instructor_info: Optional[Dict[str, Any]] = None,
) -> Dict[str, Any]:
    """
    ë°±ì—”ë“œ A: ìë™í™” íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
    
    Background pipeline: STT â†’ PDF ì²˜ë¦¬ â†’ í˜ë¥´ì†Œë‚˜ ì¶”ì¶œ â†’ RAG ì¸ì œìŠ¤íŠ¸
    
    ì´ í•¨ìˆ˜ëŠ” ìˆœìˆ˜ AI ì²˜ë¦¬ ë¡œì§ë§Œ ë‹´ë‹¹í•©ë‹ˆë‹¤.
    DB ì‘ì—…(Course, Video ëª¨ë¸ ìƒì„± ë“±)ì€ ë°±ì—”ë“œ Bì˜ ì±…ì„ì…ë‹ˆë‹¤.
    
    Args:
        course_id: ê°•ì˜ ID
        instructor_id: ê°•ì‚¬ ID
        video_path: ë¹„ë””ì˜¤/ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ì„ íƒì )
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ì„ íƒì )
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ (ì„ íƒì )
        smi_path: SMI ìë§‰ íŒŒì¼ ê²½ë¡œ (ì„ íƒì , ì œê³µ ì‹œ STTë¥¼ ê±´ë„ˆëœ€)
        update_progress: ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ì½œë°± í•¨ìˆ˜ (progress: int, message: str) -> None
    
    Returns:
        {
            "status": "completed" | "error",
            "ingested_count": int,
            "error": str (optional)
        }
    """
    settings = AISettings()
    pipeline = RAGPipeline(settings)
    
    try:
        texts: List[str] = []
        ingested_count = 0
        persona_profile_json = None  # Style Analyzer ê²°ê³¼ (ì´ˆê¸°í™”)

        # 1. Transcript ìƒì„± (SMI ìš°ì„ , ì—†ìœ¼ë©´ STT)
        # SMIê°€ ìˆìœ¼ë©´ STTë¥¼ ê±´ë„ˆë›°ê³  ìë§‰ì„ transcriptë¡œ ì‚¬ìš©
        transcript_text = ""
        segments: List[Dict[str, Any]] = []
        transcript_path = None

        # SMI ê²½ë¡œ ì •ê·œí™”/ëŒ€ì²´ ê²½ë¡œ íƒìƒ‰
        if smi_path:
            if not isinstance(smi_path, Path):
                smi_path = Path(smi_path)
            if not smi_path.is_absolute():
                smi_path = smi_path.resolve()
            print(f"[{course_id}] ğŸ“ SMI path: {smi_path}")
            print(f"[{course_id}] ğŸ“ SMI exists: {smi_path.exists()}")

            if not smi_path.exists():
                try:
                    from core.config import AppSettings
                    app_settings = AppSettings()
                    potential_path = app_settings.uploads_dir / instructor_id / course_id / smi_path.name
                    if potential_path.exists():
                        smi_path = potential_path.resolve()
                        print(f"[{course_id}] ğŸ“ Found SMI at alternative path: {smi_path}")
                    else:
                        raise FileNotFoundError(f"SMI file not found: {smi_path} (also tried: {potential_path})")
                except Exception as e:
                    print(f"[{course_id}] âŒ Error finding SMI file: {e}")
                    raise

        # STTìš© media_path ì •ê·œí™” (SMIê°€ ì—†ì„ ë•Œë§Œ ì‚¬ìš©)
        # ë¹„ë””ì˜¤ëŠ” í”„ë¡ íŠ¸ì—”ë“œ ì˜ìƒ ì¶œë ¥ìš©ì´ë¯€ë¡œ STTí•˜ì§€ ì•ŠìŒ (ì˜¤ë””ì˜¤ íŒŒì¼ë§Œ STT)
        media_path = audio_path  # video_pathëŠ” STTì—ì„œ ì œì™¸
        
        # ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        if media_path:
            if not isinstance(media_path, Path):
                media_path = Path(media_path)
            if not media_path.is_absolute():
                media_path = media_path.resolve()
            print(f"[{course_id}] ğŸ“ Media path: {media_path}")
            print(f"[{course_id}] ğŸ“ Media exists: {media_path.exists()}")
            
            # íŒŒì¼ì´ ì—†ìœ¼ë©´ ëŒ€ì²´ ê²½ë¡œ ì‹œë„
            if not media_path.exists():
                try:
                    from core.config import AppSettings
                    app_settings = AppSettings()
                    potential_path = app_settings.uploads_dir / instructor_id / course_id / media_path.name
                    if potential_path.exists():
                        media_path = potential_path.resolve()
                        print(f"[{course_id}] ğŸ“ Found media at alternative path: {media_path}")
                    else:
                        print(f"[{course_id}] âŒ Media file not found: {media_path} (also tried: {potential_path})")
                        raise FileNotFoundError(f"Media file not found: {media_path}")
                except Exception as e:
                    print(f"[{course_id}] âŒ Error finding media file: {e}")
                    raise
        
        # SMIê°€ ìˆìœ¼ë©´ ì—¬ê¸°ì„œ transcript ìƒì„±/ì €ì¥
        if smi_path and smi_path.exists():
            try:
                from ai.services.smi_parser import parse_smi_file
                import json
                from core.config import AppSettings

                if update_progress:
                    update_progress(15, "SMI ìë§‰ íŒŒì¼ íŒŒì‹± ì¤‘...")
                print(f"[{course_id}] ğŸ“ SMI ìë§‰ ê¸°ë°˜ transcript ìƒì„± ì‹œì‘: {smi_path.name}")
                transcript_result = parse_smi_file(smi_path)
                transcript_text = transcript_result.get("text", "") or ""
                segments = transcript_result.get("segments", []) or []
                print(f"[{course_id}] âœ… SMI parsed - text length: {len(transcript_text)}, segments: {len(segments)}")
                
                if update_progress:
                    update_progress(30, "SMI ìë§‰ íŒŒì‹± ì™„ë£Œ, ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì¤€ë¹„ ì¤‘...")

                if not transcript_text.strip():
                    raise ValueError(f"[{course_id}] âŒ SMI íŒŒì‹± ê²°ê³¼ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

                app_settings = AppSettings()
                course_dir = app_settings.uploads_dir / instructor_id / course_id
                course_dir.mkdir(parents=True, exist_ok=True)

                transcript_filename = f"transcript_{smi_path.stem}.json"
                transcript_file_path = course_dir / transcript_filename

                transcript_data = {
                    "text": transcript_text,
                    "segments": segments,
                    "source_file": smi_path.name,
                    "course_id": course_id,
                    "instructor_id": instructor_id,
                }

                with transcript_file_path.open("w", encoding="utf-8") as f:
                    json.dump(transcript_data, f, ensure_ascii=False, indent=2)

                if transcript_file_path.exists():
                    transcript_path = str(transcript_file_path)
                    print(f"[{course_id}] âœ… SMI transcript JSON saved: {transcript_path}")

                # persona ìƒ˜í”Œ + ì„¸ê·¸ë¨¼íŠ¸ ì¸ì œìŠ¤íŠ¸
                texts.append(transcript_text)
                print(f"[{course_id}] ğŸ“ {len(segments)}ê°œ ìë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì¸ì œìŠ¤íŠ¸ ì‹œì‘...")
                total_segments = len(segments)
                batch_texts = []
                batch_metas = []
                batch_size = 20
                for idx, seg in enumerate(segments):
                    seg_text = seg.get("text", "")
                    if not seg_text:
                        continue
                    seg_meta = {
                        "course_id": course_id,
                        "instructor_id": instructor_id,
                        "source": smi_path.name,
                        "start_time": seg.get("start"),
                        "end_time": seg.get("end"),
                        "segment_index": idx,
                        "start_formatted": seg.get("start_formatted"),
                        "end_formatted": seg.get("end_formatted"),
                        "type": "subtitle_segment",
                    }
                    batch_texts.append(seg_text)
                    batch_metas.append(seg_meta)
                    
                    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (30% ~ 60%)
                    if update_progress and total_segments > 0:
                        embedding_progress = 30 + int((idx + 1) / total_segments * 30)
                        update_progress(embedding_progress, f"ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì¤‘... ({idx + 1}/{total_segments})")

                    # ë°°ì¹˜ ì¸ì œìŠ¤íŠ¸
                    is_last = idx == total_segments - 1
                    if batch_texts and (len(batch_texts) >= batch_size or is_last):
                        try:
                            result = pipeline.ingest_texts_with_metadatas(
                                batch_texts,
                                course_id=course_id,
                                metadatas=batch_metas,
                            )
                            ingested_count += result.get("ingested", 0)
                        except Exception as batch_error:
                            print(f"[{course_id}] âš ï¸ SMI ì„¸ê·¸ë¨¼íŠ¸ ë°°ì¹˜ ì¸ì œìŠ¤íŠ¸ ì˜¤ë¥˜: {batch_error}")
                            for retry_text, retry_meta in zip(batch_texts, batch_metas):
                                try:
                                    result = pipeline.ingest_texts(
                                        [retry_text],
                                        course_id=course_id,
                                        metadata=retry_meta,
                                    )
                                    ingested_count += result.get("ingested", 0)
                                except Exception as seg_error:
                                    print(f"[{course_id}] âš ï¸ SMI ì„¸ê·¸ë¨¼íŠ¸ ì¸ì œìŠ¤íŠ¸ ì¬ì‹œë„ ì˜¤ë¥˜: {seg_error}")
                                    continue
                        finally:
                            batch_texts = []
                            batch_metas = []
                print(f"[{course_id}] âœ… ìë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì¸ì œìŠ¤íŠ¸ ì™„ë£Œ")
                if update_progress:
                    update_progress(60, "ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì™„ë£Œ")
                    
            except Exception as e:
                error_msg = f"[{course_id}] âŒ SMI ì²˜ë¦¬ ì˜¤ë¥˜ ({smi_path.name if smi_path else 'unknown'}): {str(e)}"
                print(error_msg)
                # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
        # SMIê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ STT ì²˜ë¦¬
        elif media_path and media_path.exists():
            try:
                if update_progress:
                    update_progress(15, "íŒŒì¼ ì¤€ë¹„ ì¤‘...")
                print(f"[{course_id}] ğŸ¤ STT ì²˜ë¦¬ ì‹œì‘: {media_path.name}")

                # ì²« ì—…ë¡œë“œì´ë¯€ë¡œ ë¬´ì¡°ê±´ STT ì‹¤í–‰
                if update_progress:
                    update_progress(20, "ìŒì„± ì¸ì‹(STT) ì‹œì‘...")
                # ê¸°ì¡´ transcriptê°€ ìˆìœ¼ë©´ í•´ì‹œ ë¹„êµ í›„ ì¬ì‚¬ìš©
                transcript_path = None
                force_retranscribe = True
                try:
                    from core.config import AppSettings
                    app_settings = AppSettings()
                    course_dir = app_settings.uploads_dir / instructor_id / course_id
                    transcript_filename = f"transcript_{media_path.stem}.json"
                    transcript_file_path = course_dir / transcript_filename

                    if transcript_file_path.exists():
                        # íŒŒì¼ í•´ì‹œ ê³„ì‚°
                        file_hash = hashlib.md5(media_path.read_bytes()).hexdigest()
                        with transcript_file_path.open("r", encoding="utf-8") as f:
                            data = json.load(f)
                        saved_hash = data.get("source_hash")
                        if saved_hash and saved_hash == file_hash:
                            transcript_path = str(transcript_file_path)
                            force_retranscribe = False
                            print(f"[{course_id}] âœ… ê¸°ì¡´ transcript ì¬ì‚¬ìš© (í•´ì‹œ ì¼ì¹˜): {transcript_path}")
                        else:
                            print(f"[{course_id}] âš ï¸ transcript í•´ì‹œ ë¶ˆì¼ì¹˜ ë˜ëŠ” ì—†ìŒ, STT ì¬ì‹¤í–‰")
                except Exception as e:
                    print(f"[{course_id}] âš ï¸ transcript ì¬ì‚¬ìš© ì²´í¬ ì‹¤íŒ¨, STT ì¬ì‹¤í–‰: {e}")

                print(f"[{course_id}] ğŸ”„ Running STT (force_retranscribe={force_retranscribe})...")
                transcript_result = transcribe_video(
                    str(media_path),
                    settings=settings,
                    instructor_id=instructor_id,
                    course_id=course_id,
                    transcript_path=transcript_path,
                    force_retranscribe=force_retranscribe
                )
                transcript_text = transcript_result.get("text", "")
                segments = transcript_result.get("segments", [])
                
                if update_progress:
                    update_progress(40, "ìŒì„± ì¸ì‹(STT) ì™„ë£Œ, ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì¤€ë¹„ ì¤‘...")

                print(f"[{course_id}] ğŸ“ STT result - text length: {len(transcript_text)}, segments: {len(segments)}")

                # STT placeholder ì²´í¬
                if "placeholder" in transcript_text.lower():
                    error_msg = f"[{course_id}] âŒ STTê°€ placeholderë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ì „ì‚¬ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                    print(error_msg)
                    raise ValueError(error_msg)

                if not transcript_text or not transcript_text.strip():
                    error_msg = f"[{course_id}] âŒ STT ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
                    print(error_msg)
                    raise ValueError(error_msg)

                print(f"[{course_id}] âœ… STT ì„±ê³µ! ì „ì‚¬ëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(transcript_text)} ë¬¸ì")

                # STT ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
                if transcript_text:
                    try:
                        from core.config import AppSettings
                        import json

                        app_settings = AppSettings()
                        course_dir = app_settings.uploads_dir / instructor_id / course_id
                        course_dir.mkdir(parents=True, exist_ok=True)

                        # transcript íŒŒì¼ëª…: transcript_{ì›ë³¸íŒŒì¼ëª…}.json
                        transcript_filename = f"transcript_{media_path.stem}.json"
                        transcript_file_path = course_dir / transcript_filename

                        # JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ì „ì²´ í…ìŠ¤íŠ¸ + ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´)
                        transcript_data = {
                            "text": transcript_text,
                            "segments": segments,
                            "source_file": media_path.name,
                            "course_id": course_id,
                            "instructor_id": instructor_id,
                            "source_hash": hashlib.md5(media_path.read_bytes()).hexdigest(),
                        }

                        print(f"[{course_id}] Attempting to save transcript to: {transcript_file_path}")
                        print(f"[{course_id}] Transcript text length: {len(transcript_text)}")

                        with transcript_file_path.open("w", encoding="utf-8") as f:
                            json.dump(transcript_data, f, ensure_ascii=False, indent=2)

                        # íŒŒì¼ì´ ì‹¤ì œë¡œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
                        if transcript_file_path.exists():
                            file_size = transcript_file_path.stat().st_size
                            transcript_path = str(transcript_file_path)
                            print(f"[{course_id}] âœ… STT transcript JSON saved successfully: {transcript_path} (size: {file_size} bytes)")
                        else:
                            print(f"[{course_id}] âŒ Transcript file was not created: {transcript_file_path}")
                    except Exception as e:
                        import traceback
                        print(f"[{course_id}] âŒ Failed to save transcript file: {e}")
                        print(f"[{course_id}] Error details: {traceback.format_exc()}")
                        # íŒŒì¼ ì €ì¥ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰

                if transcript_text:
                    # ë³‘í•© í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ persona ìƒì„±ìš© ìƒ˜í”Œì— ì¶”ê°€
                    texts.append(transcript_text)

                    # ì„¸ê·¸ë¨¼íŠ¸ë³„ ë©”íƒ€ë°ì´í„° í¬í•¨í•˜ì—¬ RAG ì¸ì œìŠ¤íŠ¸
                    print(f"[{course_id}] ğŸ“ {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì¸ì œìŠ¤íŠ¸ ì‹œì‘...")
                    total_segments = len(segments)
                    batch_texts = []
                    batch_metas = []
                    batch_size = 20
                    for idx, seg in enumerate(segments):
                        seg_text = seg.get("text", "")
                        if not seg_text:
                            continue

                        seg_meta = {
                            "course_id": course_id,
                            "instructor_id": instructor_id,
                            "source": media_path.name,
                            "start_time": seg.get("start"),
                            "end_time": seg.get("end"),
                            "segment_index": idx,
                            "type": "video_segment" if video_path else "audio_segment",
                        }

                        batch_texts.append(seg_text)
                        batch_metas.append(seg_meta)
                        
                        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (40% ~ 70%)
                        if update_progress and total_segments > 0:
                            embedding_progress = 40 + int((idx + 1) / total_segments * 30)
                            update_progress(embedding_progress, f"ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì¤‘... ({idx + 1}/{total_segments})")

                        # ë°°ì¹˜ ì¸ì œìŠ¤íŠ¸
                        is_last = idx == total_segments - 1
                        if batch_texts and (len(batch_texts) >= batch_size or is_last):
                            try:
                                result = pipeline.ingest_texts_with_metadatas(
                                    batch_texts,
                                    course_id=course_id,
                                    metadatas=batch_metas,
                                )
                                ingested_count += result.get("ingested", 0)
                            except Exception as batch_error:
                                print(f"[{course_id}] âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ ë°°ì¹˜ ì¸ì œìŠ¤íŠ¸ ì˜¤ë¥˜: {batch_error}")
                                for retry_text, retry_meta in zip(batch_texts, batch_metas):
                                    try:
                                        result = pipeline.ingest_texts(
                                            [retry_text],
                                            course_id=course_id,
                                            metadata=retry_meta,
                                        )
                                        ingested_count += result.get("ingested", 0)
                                    except Exception as seg_error:
                                        print(f"[{course_id}] âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ ì¸ì œìŠ¤íŠ¸ ì¬ì‹œë„ ì˜¤ë¥˜: {seg_error}")
                                        continue
                            finally:
                                batch_texts = []
                                batch_metas = []

                    print(f"[{course_id}] âœ… ì„¸ê·¸ë¨¼íŠ¸ ì¸ì œìŠ¤íŠ¸ ì™„ë£Œ")
                    if update_progress:
                        update_progress(70, "ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì™„ë£Œ")
                else:
                    print(f"[{course_id}] âš ï¸ STT ê²°ê³¼ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {media_path.name}")

            except Exception as e:
                error_msg = f"[{course_id}] âŒ STT ì²˜ë¦¬ ì˜¤ë¥˜ ({media_path.name}): {str(e)}"
                print(error_msg)
                # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
        
        # 2. PDF ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ ì„¤ëª…)
        if pdf_path and pdf_path.exists():
            try:
                if update_progress:
                    update_progress(70, "PDF ì²˜ë¦¬ ì‹œì‘...")
                print(f"[{course_id}] ğŸ“„ PDF ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì‹œì‘: {pdf_path.name}")
                print(f"[{course_id}] ğŸ“„ ì´ë¯¸ì§€ ì¶”ì¶œ í™œì„±í™”: extract_images=True")
                # PDF ì²˜ë¦¬ ëª¨ë“ˆì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ìŠ¤í‚µ
                try:
                    from ai.services.pdf import extract_pdf_content
                    pdf_result = extract_pdf_content(str(pdf_path), settings=settings, extract_images=True)
                    pdf_texts = pdf_result.get("texts", [])
                    pdf_metadata_list = pdf_result.get("metadata", [])
                    print(f"[{course_id}] ğŸ“„ PDF ì²˜ë¦¬ ì™„ë£Œ: {len(pdf_texts)}ê°œ í˜ì´ì§€ ì¶”ì¶œë¨")
                    
                    if pdf_texts:
                        # PDF í…ìŠ¤íŠ¸ë¥¼ persona ìƒì„±ìš© ìƒ˜í”Œì— ì¶”ê°€
                        texts.extend(pdf_texts)
                        
                        # í˜ì´ì§€ë³„ë¡œ ê°œë³„ RAG ì¸ì œìŠ¤íŠ¸ (í˜ì´ì§€ ë²ˆí˜¸ ë“± ë©”íƒ€ë°ì´í„° í¬í•¨)
                        print(f"[{course_id}] ğŸ–¼ï¸ PDF {len(pdf_texts)}ê°œ í˜ì´ì§€ ì¸ì œìŠ¤íŠ¸ ì‹œì‘...")
                        total_pages = len(pdf_texts)
                        batch_texts = []
                        batch_metas = []
                        batch_size = 10
                        for page_idx, (pdf_text, pdf_meta) in enumerate(zip(pdf_texts, pdf_metadata_list)):
                            try:
                                page_num = pdf_meta.get("page_number")
                                if page_num is None:
                                    # pdf_metaì— page_numberê°€ ì—†ìœ¼ë©´ page_idx + 1 ì‚¬ìš©
                                    page_num = page_idx + 1
                                    print(f"[{course_id}] âš ï¸ PDF ë©”íƒ€ë°ì´í„°ì— page_numberê°€ ì—†ì–´ì„œ {page_num}ë¡œ ì„¤ì •")

                                page_meta = {
                                    "course_id": course_id,
                                    "instructor_id": instructor_id,
                                    "source": pdf_path.name,
                                    "page_number": page_num,  # ëª…ì‹œì ìœ¼ë¡œ intë¡œ ì €ì¥
                                    "type": "pdf_page",
                                }
                                print(f"[{course_id}] ğŸ“„ PDF í˜ì´ì§€ {page_num} ì¸ì œìŠ¤íŠ¸: {pdf_text[:50]}...")

                                batch_texts.append(pdf_text)
                                batch_metas.append(page_meta)
                                
                                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (70% ~ 75%)
                                if update_progress and total_pages > 0:
                                    pdf_progress = 70 + int((page_idx + 1) / total_pages * 5)
                                    update_progress(pdf_progress, f"PDF í˜ì´ì§€ ì²˜ë¦¬ ì¤‘... ({page_idx + 1}/{total_pages})")
                                
                                # ë°°ì¹˜ ì²˜ë¦¬
                                is_last = page_idx == total_pages - 1
                                if batch_texts and (len(batch_texts) >= batch_size or is_last):
                                    try:
                                        print(f"[{course_id}] ğŸ“¤ PDF ë°°ì¹˜ ì¸ì œìŠ¤íŠ¸ ì‹œì‘: {len(batch_texts)}ê°œ í˜ì´ì§€ (course_id={course_id})")
                                        for bm in batch_metas:
                                            print(f"[{course_id}] ğŸ“„ ë°°ì¹˜ ë©”íƒ€ë°ì´í„°: page_number={bm.get('page_number')} (type: {type(bm.get('page_number')).__name__}), type={bm.get('type')}, course_id={bm.get('course_id')}")
                                        result = pipeline.ingest_texts_with_metadatas(
                                            batch_texts,
                                            course_id=course_id,
                                            metadatas=batch_metas,
                                        )
                                        ingested_count += result.get("ingested", 0)
                                        print(f"[{course_id}] âœ… PDF ë°°ì¹˜ ì¸ì œìŠ¤íŠ¸ ì„±ê³µ: {result.get('ingested', 0)}ê°œ ì €ì¥ë¨")
                                    except Exception as batch_error:
                                        print(f"[{course_id}] âš ï¸ PDF ë°°ì¹˜ ì¸ì œìŠ¤íŠ¸ ì˜¤ë¥˜: {batch_error}")
                                        import traceback
                                        print(f"[{course_id}] ë°°ì¹˜ ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
                                        # ë°°ì¹˜ ì‹¤íŒ¨ ì‹œ í˜ì´ì§€ ë‹¨ìœ„ë¡œ ì¬ì‹œë„
                                        for retry_text, retry_meta in zip(batch_texts, batch_metas):
                                            try:
                                                print(f"[{course_id}] ğŸ”„ PDF í˜ì´ì§€ ì¬ì‹œë„: page_number={retry_meta.get('page_number')}")
                                                result = pipeline.ingest_texts(
                                                    [retry_text],
                                                    course_id=course_id,
                                                    metadata=retry_meta,
                                                )
                                                ingested_count += result.get("ingested", 0)
                                                print(f"[{course_id}] âœ… PDF í˜ì´ì§€ ì¬ì‹œë„ ì„±ê³µ: {result.get('ingested', 0)}ê°œ ì €ì¥ë¨")
                                            except Exception as retry_error:
                                                print(f"[{course_id}] âš ï¸ PDF í˜ì´ì§€ ì¸ì œìŠ¤íŠ¸ ì¬ì‹œë„ ì˜¤ë¥˜: {retry_error}")
                                                import traceback
                                                print(f"[{course_id}] ì¬ì‹œë„ ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
                                                continue
                                    finally:
                                        batch_texts = []
                                        batch_metas = []
                            except Exception as page_error:
                                print(f"[{course_id}] âš ï¸ PDF í˜ì´ì§€ {page_idx + 1} ì¸ì œìŠ¤íŠ¸ ì˜¤ë¥˜: {page_error}")
                                # ê°œë³„ í˜ì´ì§€ ì˜¤ë¥˜ëŠ” ê±´ë„ˆë›°ê³  ê³„ì† ì§„í–‰
                                continue
                        
                        print(f"[{course_id}] âœ… PDF í˜ì´ì§€ ì¸ì œìŠ¤íŠ¸ ì™„ë£Œ ({len(pdf_texts)}ê°œ í˜ì´ì§€)")
                    else:
                        print(f"[{course_id}] âš ï¸ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {pdf_path.name}")
                        # PDF í…ìŠ¤íŠ¸ê°€ ì—†ì–´ë„ ê³„ì† ì§„í–‰
                except ImportError:
                    print(f"[{course_id}] âš ï¸ PDF ì²˜ë¦¬ ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤. PDF ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                    # PDF ì²˜ë¦¬ ëª¨ë“ˆì´ ì—†ì–´ë„ ê³„ì† ì§„í–‰
                except Exception as pdf_error:
                    # PDF ì²˜ë¦¬ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ê³„ì† ì§„í–‰
                    error_msg = f"[{course_id}] âš ï¸ PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(pdf_error)}"
                    print(error_msg)
                    import traceback
                    print(f"[{course_id}] PDF ì˜¤ë¥˜ ìƒì„¸: {traceback.format_exc()}")
                    # PDF ì²˜ë¦¬ëŠ” ì‹¤íŒ¨í–ˆì§€ë§Œ ë‚˜ë¨¸ì§€ ì²˜ë¦¬ ê³„ì† ì§„í–‰
                        
            except Exception as e:
                error_msg = f"[{course_id}] âŒ PDF ì²˜ë¦¬ ì˜¤ë¥˜ ({pdf_path.name}): {str(e)}"
                print(error_msg)
                # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
        
        # 3. Style Analyzer ì‹¤í–‰ (ê°•ì˜ ëª©ë¡ ë‹¨ìœ„ ë§íˆ¬ ê´€ë¦¬)
        # - ë¶€ëª¨ ê°•ì˜(parent_course_idê°€ null)ì— persona_profile ì €ì¥
        # - ì±•í„°(parent_course_idê°€ ìˆìŒ)ëŠ” ë¶€ëª¨ ê°•ì˜ì˜ persona_profile ì¬ì‚¬ìš©
        persona_profile_json = None
        if segments and len(segments) > 0:
            if update_progress:
                update_progress(75, "ê°•ì‚¬ ìŠ¤íƒ€ì¼ ë¶„ì„ ì¤‘...")
            
            # í˜„ì¬ courseê°€ ì±•í„°ì¸ì§€ ë¶€ëª¨ ê°•ì˜ì¸ì§€ í™•ì¸
            parent_course_id = None
            is_chapter = False
            try:
                from core.db import engine
                from sqlmodel import Session
                from core.models import Course
                
                with Session(engine) as db_session:
                    current_course = db_session.get(Course, course_id)
                    if current_course:
                        parent_course_id = current_course.parent_course_id
                        is_chapter = parent_course_id is not None
                        if is_chapter:
                            print(f"[{course_id}] ğŸ“š ì±•í„° ê°ì§€ë¨ (ë¶€ëª¨ ê°•ì˜: {parent_course_id})")
                        else:
                            print(f"[{course_id}] ğŸ“– ë¶€ëª¨ ê°•ì˜ ê°ì§€ë¨")
            except Exception as db_e:
                print(f"[{course_id}] âš ï¸ Course ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {db_e}")
                # DB ì¡°íšŒ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
            
            # ì±•í„°ì¸ ê²½ìš°: ë¶€ëª¨ ê°•ì˜ì˜ persona_profile ì¬ì‚¬ìš©
            if is_chapter and parent_course_id:
                try:
                    from core.db import engine
                    from sqlmodel import Session
                    from core.models import Course
                    
                    with Session(engine) as db_session:
                        parent_course = db_session.get(Course, parent_course_id)
                        if parent_course and parent_course.persona_profile:
                            persona_profile_json = parent_course.persona_profile
                            print(f"[{course_id}] âœ… ë¶€ëª¨ ê°•ì˜ ë§íˆ¬ ë°œê²¬ (ì¬ì‚¬ìš©): {parent_course_id}")
                            print(f"[{course_id}] â™»ï¸ ë¶€ëª¨ ê°•ì˜ ë§íˆ¬ ì¬ì‚¬ìš© (API í˜¸ì¶œ ìƒëµ)")
                        else:
                            print(f"[{course_id}] âš ï¸ ë¶€ëª¨ ê°•ì˜({parent_course_id})ì˜ ë§íˆ¬ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
                            # ë¶€ëª¨ ê°•ì˜ ë§íˆ¬ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ë¶„ì„ (ë¶€ëª¨ ê°•ì˜ì— ì €ì¥)
                            is_chapter = False  # ë¶€ëª¨ ê°•ì˜ì²˜ëŸ¼ ì²˜ë¦¬
                            parent_course_id = None
                except Exception as db_e:
                    print(f"[{course_id}] âš ï¸ ë¶€ëª¨ ê°•ì˜ ë§íˆ¬ í™•ì¸ ì‹¤íŒ¨: {db_e}")
                    # ë¶€ëª¨ ê°•ì˜ ë§íˆ¬ í™•ì¸ ì‹¤íŒ¨ ì‹œ ìƒˆë¡œ ë¶„ì„
                    is_chapter = False
                    parent_course_id = None
            
            # ë¶€ëª¨ ê°•ì˜ì¸ ê²½ìš° (ë˜ëŠ” ë¶€ëª¨ ê°•ì˜ ë§íˆ¬ê°€ ì—†ëŠ” ì±•í„°): ë¶€ëª¨ ê°•ì˜ì˜ persona_profile í™•ì¸
            if not is_chapter:
                target_course_id = course_id  # ë¶€ëª¨ ê°•ì˜ ID ì‚¬ìš©
                try:
                    from core.db import engine
                    from sqlmodel import Session
                    from core.models import Course
                    
                    with Session(engine) as db_session:
                        target_course = db_session.get(Course, target_course_id)
                        if target_course and target_course.persona_profile:
                            # ë¶€ëª¨ ê°•ì˜ ë§íˆ¬ê°€ ì´ë¯¸ ìˆìœ¼ë©´ ì¬ì‚¬ìš©
                            persona_profile_json = target_course.persona_profile
                            print(f"[{course_id}] âœ… ë¶€ëª¨ ê°•ì˜ ë§íˆ¬ ë°œê²¬ (ì¬ì‚¬ìš©): {target_course_id}")
                            print(f"[{course_id}] â™»ï¸ ë¶€ëª¨ ê°•ì˜ ë§íˆ¬ ì¬ì‚¬ìš© (API í˜¸ì¶œ ìƒëµ)")
                        else:
                            # ë¶€ëª¨ ê°•ì˜ ë§íˆ¬ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ë¶„ì„
                            print(f"[{course_id}] ğŸ§‘â€ğŸ« Style Analyzer ì‹¤í–‰ (ì´ˆë°˜ 10~20ë¶„ ë¶„ì„)...")
                            try:
                                persona_profile = analyze_instructor_style(segments, settings=settings)
                                persona_profile_json = json.dumps(persona_profile, ensure_ascii=False)
                                print(f"[{course_id}] âœ… Style Analyzer ì™„ë£Œ: {persona_profile_json[:100]}...")
                                
                                # ë¶€ëª¨ ê°•ì˜ì˜ persona_profileì— ì €ì¥
                                try:
                                    with Session(engine) as db_session:
                                        target_course = db_session.get(Course, target_course_id)
                                        if target_course:
                                            target_course.persona_profile = persona_profile_json
                                            db_session.add(target_course)
                                            db_session.commit()
                                            db_session.refresh(target_course)
                                            print(f"[{course_id}] âœ… ë¶€ëª¨ ê°•ì˜ ë§íˆ¬ë¥¼ Course DBì— ì €ì¥ ì™„ë£Œ (course_id: {target_course_id})")
                                        else:
                                            print(f"[{course_id}] âš ï¸ ë¶€ëª¨ ê°•ì˜({target_course_id})ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë§íˆ¬ë¥¼ ì €ì¥í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                                except Exception as db_e:
                                    print(f"[{course_id}] âš ï¸ ë¶€ëª¨ ê°•ì˜ ë§íˆ¬ DB ì €ì¥ ì‹¤íŒ¨: {db_e}")
                                    # DB ì €ì¥ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                                
                            except Exception as e:
                                error_msg = f"[{course_id}] âŒ Style Analyzer ì˜¤ë¥˜: {str(e)}"
                                print(error_msg)
                                # Style Analyzer ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                except Exception as db_e:
                    print(f"[{course_id}] âš ï¸ ë¶€ëª¨ ê°•ì˜ ë§íˆ¬ í™•ì¸ ì‹¤íŒ¨: {db_e}")
                    # DB ì¡°íšŒ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
        
        # 4. í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ìƒì„± ë° RAG ì¸ì œìŠ¤íŠ¸
        if texts:
            if update_progress:
                update_progress(80, "í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
            print(f"[{course_id}] ğŸ§‘â€ğŸ« í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œì‘...")
            # Style Analyzer ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            try:
                if persona_profile_json:
                    # Style Analyzer ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì—¬ í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
                    from ai.style_analyzer import create_persona_prompt
                    persona_dict = json.loads(persona_profile_json)
                    persona_prompt = create_persona_prompt(persona_dict)
                    # âš ï¸ ê°•ì‚¬ ì •ë³´ëŠ” ChromaDBì— ì €ì¥í•˜ì§€ ì•ŠìŒ (DBì—ì„œ ë™ì ìœ¼ë¡œ ë¡œë“œ)
                    # instructor_infoëŠ” ë¶„ì„ ì‹œì—ë§Œ ì°¸ê³ í•˜ê³ , í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ì—ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ
                else:
                    # ê¸°ì¡´ ë°©ì‹ (fallback) - ê°•ì‚¬ ì •ë³´ëŠ” í¬í•¨í•˜ì§€ ì•ŠìŒ (DBì—ì„œ ë™ì ìœ¼ë¡œ ë¡œë“œ)
                    persona_prompt = pipeline.generate_persona_prompt(
                        course_id=course_id,
                        sample_texts=texts,
                        instructor_info=None  # ChromaDBì— ì €ì¥í•˜ì§€ ì•ŠìŒ
                    )
                
                if update_progress:
                    update_progress(85, "í˜ë¥´ì†Œë‚˜ ì €ì¥ ì¤‘...")
                # í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë²¡í„° DBì— ì €ì¥
                result = pipeline.ingest_texts(
                    [persona_prompt],
                    course_id=course_id,
                    metadata={
                        "course_id": course_id,
                        "instructor_id": instructor_id,
                        "type": "persona",
                    },
                )
                ingested_count += result.get("ingested", 0)
                print(f"[{course_id}] âœ… í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ì €ì¥ ì™„ë£Œ")
                if update_progress:
                    update_progress(95, "ìµœì¢… ì²˜ë¦¬ ì¤‘...")
                
            except Exception as e:
                error_msg = f"[{course_id}] âŒ í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}"
                print(error_msg)
                # í˜ë¥´ì†Œë‚˜ ì¶”ì¶œ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
        else:
            print(f"[{course_id}] âš ï¸ ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        return {
            "status": "completed",
            "ingested_count": ingested_count,
            "transcript_path": transcript_path,  # STT ê²°ê³¼ íŒŒì¼ ê²½ë¡œ (ìˆëŠ” ê²½ìš°)
            "persona_profile": persona_profile_json,  # Style Analyzer ê²°ê³¼ (JSON ë¬¸ìì—´, backBê°€ DBì— ì €ì¥)
        }
        
    except Exception as e:
        error_msg = f"[{course_id}] âŒ íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì˜¤ë¥˜: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        return {
            "status": "error",
            "ingested_count": ingested_count if 'ingested_count' in locals() else 0,
            "error": error_msg,
        }
