"""
ë°±ì—”ë“œ A: ìë™í™” íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- STT â†’ PDF ì²˜ë¦¬ â†’ í˜ë¥´ì†Œë‚˜ ì¶”ì¶œ â†’ RAG ì¸ì œìŠ¤íŠ¸
- ìˆœìˆ˜ AI ì²˜ë¦¬ ë¡œì§ë§Œ ë‹´ë‹¹ (DB ì‘ì—… ì œì™¸)
"""
from pathlib import Path
from typing import Optional, List, Dict, Any, Callable

from ai.config import AISettings
from ai.pipelines.rag import RAGPipeline
from ai.services.stt import transcribe_video
from ai.style_analyzer import analyze_instructor_style
import json


def process_course_assets(
    *,
    course_id: str,
    instructor_id: str,
    video_path: Optional[Path] = None,
    audio_path: Optional[Path] = None,
    pdf_path: Optional[Path] = None,
    smi_path: Optional[Path] = None,
    update_progress: Optional[Callable[[int, str], None]] = None,
) -> Dict[str, Any]:
    """
    ë°±ì—”ë“œ A: ìë™í™” íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
    
    Background pipeline: STT â†’ PDF ì²˜ë¦¬ â†’ í˜ë¥´ì†Œë‚˜ ì¶”ì¶œ â†’ RAG ì¸ì œìŠ¤íŠ¸
    
    ì´ í•¨ìˆ˜ëŠ” ìˆœìˆ˜ AI ì²˜ë¦¬ ë¡œì§ë§Œ ë‹´ë‹¹í•©ë‹ˆë‹¤.
    DB ì‘ì—…(Course, Video ëª¨ë¸ ìƒì„± ë“±)ì€ ë°±ì—”ë“œ Bì˜ ì±…ì„ì…ë‹ˆë‹¤.
    
    Args:
        course_id: ê°•ì˜ ID
        instructor_id: ê°•ì‚¬ ID
        video_path: ë¹„ë””ì˜¤/ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ì„ íƒì )
        audio_path: ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ì„ íƒì )
        pdf_path: PDF íŒŒì¼ ê²½ë¡œ (ì„ íƒì )
        smi_path: SMI ìë§‰ íŒŒì¼ ê²½ë¡œ (ì„ íƒì , ì œê³µ ì‹œ STTë¥¼ ê±´ë„ˆëœ€)
        update_progress: ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ì½œë°± í•¨ìˆ˜ (progress: int, message: str) -> None
    
    Returns:
        {
            "status": "completed" | "error",
            "ingested_count": int,
            "error": str (optional)
        }
    """
    settings = AISettings()
    pipeline = RAGPipeline(settings)
    
    try:
        texts: List[str] = []
        ingested_count = 0
        persona_profile_json = None  # Style Analyzer ê²°ê³¼ (ì´ˆê¸°í™”)

        # 1. Transcript ìƒì„± (SMI ìš°ì„ , ì—†ìœ¼ë©´ STT)
        # SMIê°€ ìˆìœ¼ë©´ STTë¥¼ ê±´ë„ˆë›°ê³  ìë§‰ì„ transcriptë¡œ ì‚¬ìš©
        transcript_text = ""
        segments: List[Dict[str, Any]] = []
        transcript_path = None

        # SMI ê²½ë¡œ ì •ê·œí™”/ëŒ€ì²´ ê²½ë¡œ íƒìƒ‰
        if smi_path:
            if not isinstance(smi_path, Path):
                smi_path = Path(smi_path)
            if not smi_path.is_absolute():
                smi_path = smi_path.resolve()
            print(f"[{course_id}] ğŸ“ SMI path: {smi_path}")
            print(f"[{course_id}] ğŸ“ SMI exists: {smi_path.exists()}")

            if not smi_path.exists():
                try:
                    from core.config import AppSettings
                    app_settings = AppSettings()
                    potential_path = app_settings.uploads_dir / instructor_id / course_id / smi_path.name
                    if potential_path.exists():
                        smi_path = potential_path.resolve()
                        print(f"[{course_id}] ğŸ“ Found SMI at alternative path: {smi_path}")
                    else:
                        raise FileNotFoundError(f"SMI file not found: {smi_path} (also tried: {potential_path})")
                except Exception as e:
                    print(f"[{course_id}] âŒ Error finding SMI file: {e}")
                    raise

        # STTìš© media_path ì •ê·œí™” (SMIê°€ ì—†ì„ ë•Œë§Œ ì‚¬ìš©)
        # ë¹„ë””ì˜¤ëŠ” í”„ë¡ íŠ¸ì—”ë“œ ì˜ìƒ ì¶œë ¥ìš©ì´ë¯€ë¡œ STTí•˜ì§€ ì•ŠìŒ (ì˜¤ë””ì˜¤ íŒŒì¼ë§Œ STT)
        media_path = audio_path  # video_pathëŠ” STTì—ì„œ ì œì™¸
        
        # ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        if media_path:
            if not isinstance(media_path, Path):
                media_path = Path(media_path)
            if not media_path.is_absolute():
                media_path = media_path.resolve()
            print(f"[{course_id}] ğŸ“ Media path: {media_path}")
            print(f"[{course_id}] ğŸ“ Media exists: {media_path.exists()}")
            
            # íŒŒì¼ì´ ì—†ìœ¼ë©´ ëŒ€ì²´ ê²½ë¡œ ì‹œë„
            if not media_path.exists():
                try:
                    from core.config import AppSettings
                    app_settings = AppSettings()
                    potential_path = app_settings.uploads_dir / instructor_id / course_id / media_path.name
                    if potential_path.exists():
                        media_path = potential_path.resolve()
                        print(f"[{course_id}] ğŸ“ Found media at alternative path: {media_path}")
                    else:
                        print(f"[{course_id}] âŒ Media file not found: {media_path} (also tried: {potential_path})")
                        raise FileNotFoundError(f"Media file not found: {media_path}")
                except Exception as e:
                    print(f"[{course_id}] âŒ Error finding media file: {e}")
                    raise
        
        # SMIê°€ ìˆìœ¼ë©´ ì—¬ê¸°ì„œ transcript ìƒì„±/ì €ì¥
        if smi_path and smi_path.exists():
            try:
                from ai.services.smi_parser import parse_smi_file
                import json
                from core.config import AppSettings

                if update_progress:
                    update_progress(15, "SMI ìë§‰ íŒŒì¼ íŒŒì‹± ì¤‘...")
                print(f"[{course_id}] ğŸ“ SMI ìë§‰ ê¸°ë°˜ transcript ìƒì„± ì‹œì‘: {smi_path.name}")
                transcript_result = parse_smi_file(smi_path)
                transcript_text = transcript_result.get("text", "") or ""
                segments = transcript_result.get("segments", []) or []
                print(f"[{course_id}] âœ… SMI parsed - text length: {len(transcript_text)}, segments: {len(segments)}")
                
                if update_progress:
                    update_progress(30, "SMI ìë§‰ íŒŒì‹± ì™„ë£Œ, ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì¤€ë¹„ ì¤‘...")

                if not transcript_text.strip():
                    raise ValueError(f"[{course_id}] âŒ SMI íŒŒì‹± ê²°ê³¼ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

                app_settings = AppSettings()
                course_dir = app_settings.uploads_dir / instructor_id / course_id
                course_dir.mkdir(parents=True, exist_ok=True)

                transcript_filename = f"transcript_{smi_path.stem}.json"
                transcript_file_path = course_dir / transcript_filename

                transcript_data = {
                    "text": transcript_text,
                    "segments": segments,
                    "source_file": smi_path.name,
                    "course_id": course_id,
                    "instructor_id": instructor_id,
                }

                with transcript_file_path.open("w", encoding="utf-8") as f:
                    json.dump(transcript_data, f, ensure_ascii=False, indent=2)

                if transcript_file_path.exists():
                    transcript_path = str(transcript_file_path)
                    print(f"[{course_id}] âœ… SMI transcript JSON saved: {transcript_path}")

                # persona ìƒ˜í”Œ + ì„¸ê·¸ë¨¼íŠ¸ ì¸ì œìŠ¤íŠ¸
                texts.append(transcript_text)
                print(f"[{course_id}] ğŸ“ {len(segments)}ê°œ ìë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì¸ì œìŠ¤íŠ¸ ì‹œì‘...")
                total_segments = len(segments)
                for idx, seg in enumerate(segments):
                    seg_text = seg.get("text", "")
                    if not seg_text:
                        continue
                    seg_meta = {
                        "course_id": course_id,
                        "instructor_id": instructor_id,
                        "source": smi_path.name,
                        "start_time": seg.get("start"),
                        "end_time": seg.get("end"),
                        "segment_index": idx,
                        "start_formatted": seg.get("start_formatted"),
                        "end_formatted": seg.get("end_formatted"),
                        "type": "subtitle_segment",
                    }
                    result = pipeline.ingest_texts(
                        [seg_text],
                        course_id=course_id,
                        metadata=seg_meta,
                    )
                    ingested_count += result.get("ingested", 0)
                    
                    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (30% ~ 60%)
                    if update_progress and total_segments > 0:
                        embedding_progress = 30 + int((idx + 1) / total_segments * 30)
                        update_progress(embedding_progress, f"ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì¤‘... ({idx + 1}/{total_segments})")
                print(f"[{course_id}] âœ… ìë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì¸ì œìŠ¤íŠ¸ ì™„ë£Œ")
                if update_progress:
                    update_progress(60, "ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì™„ë£Œ")
                    
            except Exception as e:
                error_msg = f"[{course_id}] âŒ SMI ì²˜ë¦¬ ì˜¤ë¥˜ ({smi_path.name if smi_path else 'unknown'}): {str(e)}"
                print(error_msg)
                # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
        # SMIê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ STT ì²˜ë¦¬
        elif media_path and media_path.exists():
            try:
                if update_progress:
                    update_progress(15, "íŒŒì¼ ì¤€ë¹„ ì¤‘...")
                print(f"[{course_id}] ğŸ¤ STT ì²˜ë¦¬ ì‹œì‘: {media_path.name}")

                # ì²« ì—…ë¡œë“œì´ë¯€ë¡œ ë¬´ì¡°ê±´ STT ì‹¤í–‰
                if update_progress:
                    update_progress(20, "ìŒì„± ì¸ì‹(STT) ì‹œì‘...")
                print(f"[{course_id}] ğŸ”„ Running STT (force_retranscribe=True)...")
                transcript_result = transcribe_video(
                    str(media_path),
                    settings=settings,
                    instructor_id=instructor_id,
                    course_id=course_id,
                    transcript_path=None,  # ê¸°ì¡´ íŒŒì¼ ë¬´ì‹œ
                    force_retranscribe=True  # ê°•ì œë¡œ STT ì‹¤í–‰
                )
                transcript_text = transcript_result.get("text", "")
                segments = transcript_result.get("segments", [])
                
                if update_progress:
                    update_progress(40, "ìŒì„± ì¸ì‹(STT) ì™„ë£Œ, ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì¤€ë¹„ ì¤‘...")

                print(f"[{course_id}] ğŸ“ STT result - text length: {len(transcript_text)}, segments: {len(segments)}")

                # STT placeholder ì²´í¬
                if "placeholder" in transcript_text.lower():
                    error_msg = f"[{course_id}] âŒ STTê°€ placeholderë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ì „ì‚¬ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                    print(error_msg)
                    raise ValueError(error_msg)

                if not transcript_text or not transcript_text.strip():
                    error_msg = f"[{course_id}] âŒ STT ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
                    print(error_msg)
                    raise ValueError(error_msg)

                print(f"[{course_id}] âœ… STT ì„±ê³µ! ì „ì‚¬ëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(transcript_text)} ë¬¸ì")

                # STT ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
                if transcript_text:
                    try:
                        from core.config import AppSettings
                        import json

                        app_settings = AppSettings()
                        course_dir = app_settings.uploads_dir / instructor_id / course_id
                        course_dir.mkdir(parents=True, exist_ok=True)

                        # transcript íŒŒì¼ëª…: transcript_{ì›ë³¸íŒŒì¼ëª…}.json
                        transcript_filename = f"transcript_{media_path.stem}.json"
                        transcript_file_path = course_dir / transcript_filename

                        # JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ì „ì²´ í…ìŠ¤íŠ¸ + ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´)
                        transcript_data = {
                            "text": transcript_text,
                            "segments": segments,
                            "source_file": media_path.name,
                            "course_id": course_id,
                            "instructor_id": instructor_id,
                        }

                        print(f"[{course_id}] Attempting to save transcript to: {transcript_file_path}")
                        print(f"[{course_id}] Transcript text length: {len(transcript_text)}")

                        with transcript_file_path.open("w", encoding="utf-8") as f:
                            json.dump(transcript_data, f, ensure_ascii=False, indent=2)

                        # íŒŒì¼ì´ ì‹¤ì œë¡œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
                        if transcript_file_path.exists():
                            file_size = transcript_file_path.stat().st_size
                            transcript_path = str(transcript_file_path)
                            print(f"[{course_id}] âœ… STT transcript JSON saved successfully: {transcript_path} (size: {file_size} bytes)")
                        else:
                            print(f"[{course_id}] âŒ Transcript file was not created: {transcript_file_path}")
                    except Exception as e:
                        import traceback
                        print(f"[{course_id}] âŒ Failed to save transcript file: {e}")
                        print(f"[{course_id}] Error details: {traceback.format_exc()}")
                        # íŒŒì¼ ì €ì¥ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰

                if transcript_text:
                    # ë³‘í•© í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ persona ìƒì„±ìš© ìƒ˜í”Œì— ì¶”ê°€
                    texts.append(transcript_text)

                    # ì„¸ê·¸ë¨¼íŠ¸ë³„ ë©”íƒ€ë°ì´í„° í¬í•¨í•˜ì—¬ RAG ì¸ì œìŠ¤íŠ¸
                    print(f"[{course_id}] ğŸ“ {len(segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ì¸ì œìŠ¤íŠ¸ ì‹œì‘...")
                    total_segments = len(segments)
                    for idx, seg in enumerate(segments):
                        seg_text = seg.get("text", "")
                        if not seg_text:
                            continue

                        seg_meta = {
                            "course_id": course_id,
                            "instructor_id": instructor_id,
                            "source": media_path.name,
                            "start_time": seg.get("start"),
                            "end_time": seg.get("end"),
                            "segment_index": idx,
                            "type": "video_segment" if video_path else "audio_segment",
                        }

                        result = pipeline.ingest_texts(
                            [seg_text],
                            course_id=course_id,
                            metadata=seg_meta,
                        )
                        ingested_count += result.get("ingested", 0)
                        
                        # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (40% ~ 70%)
                        if update_progress and total_segments > 0:
                            embedding_progress = 40 + int((idx + 1) / total_segments * 30)
                            update_progress(embedding_progress, f"ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì¤‘... ({idx + 1}/{total_segments})")

                    print(f"[{course_id}] âœ… ì„¸ê·¸ë¨¼íŠ¸ ì¸ì œìŠ¤íŠ¸ ì™„ë£Œ")
                    if update_progress:
                        update_progress(70, "ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì™„ë£Œ")
                else:
                    print(f"[{course_id}] âš ï¸ STT ê²°ê³¼ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {media_path.name}")

            except Exception as e:
                error_msg = f"[{course_id}] âŒ STT ì²˜ë¦¬ ì˜¤ë¥˜ ({media_path.name}): {str(e)}"
                print(error_msg)
                # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
        
        # 2. PDF ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ (í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ ì„¤ëª…)
        if pdf_path and pdf_path.exists():
            try:
                if update_progress:
                    update_progress(70, "PDF ì²˜ë¦¬ ì‹œì‘...")
                print(f"[{course_id}] ğŸ“„ PDF ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬ ì‹œì‘: {pdf_path.name}")
                # PDF ì²˜ë¦¬ ëª¨ë“ˆì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ìŠ¤í‚µ
                try:
                    from ai.services.pdf import extract_pdf_content
                    pdf_result = extract_pdf_content(str(pdf_path), settings=settings, extract_images=True)
                    pdf_texts = pdf_result.get("texts", [])
                    pdf_metadata_list = pdf_result.get("metadata", [])
                    
                    if pdf_texts:
                        # PDF í…ìŠ¤íŠ¸ë¥¼ persona ìƒì„±ìš© ìƒ˜í”Œì— ì¶”ê°€
                        texts.extend(pdf_texts)
                        
                        # í˜ì´ì§€ë³„ë¡œ ê°œë³„ RAG ì¸ì œìŠ¤íŠ¸ (í˜ì´ì§€ ë²ˆí˜¸ ë“± ë©”íƒ€ë°ì´í„° í¬í•¨)
                        print(f"[{course_id}] ğŸ–¼ï¸ PDF {len(pdf_texts)}ê°œ í˜ì´ì§€ ì¸ì œìŠ¤íŠ¸ ì‹œì‘...")
                        total_pages = len(pdf_texts)
                        for page_idx, (pdf_text, pdf_meta) in enumerate(zip(pdf_texts, pdf_metadata_list)):
                            page_meta = {
                                "course_id": course_id,
                                "instructor_id": instructor_id,
                                "source": pdf_path.name,
                                "page_number": pdf_meta.get("page_number"),
                                "type": "pdf_page",
                            }
                            
                            result = pipeline.ingest_texts(
                                [pdf_text],
                                course_id=course_id,
                                metadata=page_meta,
                            )
                            ingested_count += result.get("ingested", 0)
                            
                            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (70% ~ 75%)
                            if update_progress and total_pages > 0:
                                pdf_progress = 70 + int((page_idx + 1) / total_pages * 5)
                                update_progress(pdf_progress, f"PDF í˜ì´ì§€ ì²˜ë¦¬ ì¤‘... ({page_idx + 1}/{total_pages})")
                        
                        print(f"[{course_id}] âœ… PDF í˜ì´ì§€ ì¸ì œìŠ¤íŠ¸ ì™„ë£Œ")
                    else:
                        print(f"[{course_id}] âš ï¸ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {pdf_path.name}")
                except ImportError:
                    print(f"[{course_id}] âš ï¸ PDF ì²˜ë¦¬ ëª¨ë“ˆì´ ì—†ìŠµë‹ˆë‹¤. PDF ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                    # PDF ì²˜ë¦¬ ëª¨ë“ˆì´ ì—†ì–´ë„ ê³„ì† ì§„í–‰
                        
            except Exception as e:
                error_msg = f"[{course_id}] âŒ PDF ì²˜ë¦¬ ì˜¤ë¥˜ ({pdf_path.name}): {str(e)}"
                print(error_msg)
                # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
        
        # 3. Style Analyzer ì‹¤í–‰ (ì´ˆë°˜ 5ë¶„ ë¶„ì„) ë° í˜ë¥´ì†Œë‚˜ ì¶”ì¶œ
        persona_profile_json = None
        if segments and len(segments) > 0:
            if update_progress:
                update_progress(75, "ê°•ì‚¬ ìŠ¤íƒ€ì¼ ë¶„ì„ ì¤‘...")
            print(f"[{course_id}] ğŸ§‘â€ğŸ« Style Analyzer ì‹¤í–‰ (ì´ˆë°˜ 5ë¶„ ë¶„ì„)...")
            try:
                persona_profile = analyze_instructor_style(segments, settings=settings)
                persona_profile_json = json.dumps(persona_profile, ensure_ascii=False)
                print(f"[{course_id}] âœ… Style Analyzer ì™„ë£Œ: {persona_profile_json[:100]}...")
                
                # persona_profileì€ ë°˜í™˜ê°’ì— í¬í•¨í•˜ì—¬ backBê°€ DBì— ì €ì¥í•˜ë„ë¡ í•¨
                
            except Exception as e:
                error_msg = f"[{course_id}] âŒ Style Analyzer ì˜¤ë¥˜: {str(e)}"
                print(error_msg)
                # Style Analyzer ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
        
        # 4. í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ìƒì„± ë° RAG ì¸ì œìŠ¤íŠ¸
        if texts:
            if update_progress:
                update_progress(80, "í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
            print(f"[{course_id}] ğŸ§‘â€ğŸ« í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œì‘...")
            # Style Analyzer ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            try:
                if persona_profile_json:
                    # Style Analyzer ê²°ê³¼ë¥¼ ì‚¬ìš©í•˜ì—¬ í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
                    from ai.style_analyzer import create_persona_prompt
                    persona_dict = json.loads(persona_profile_json)
                    persona_prompt = create_persona_prompt(persona_dict)
                else:
                    # ê¸°ì¡´ ë°©ì‹ (fallback)
                    persona_prompt = pipeline.generate_persona_prompt(
                        course_id=course_id, sample_texts=texts
                    )
                
                if update_progress:
                    update_progress(85, "í˜ë¥´ì†Œë‚˜ ì €ì¥ ì¤‘...")
                # í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë²¡í„° DBì— ì €ì¥
                result = pipeline.ingest_texts(
                    [persona_prompt],
                    course_id=course_id,
                    metadata={
                        "course_id": course_id,
                        "instructor_id": instructor_id,
                        "type": "persona",
                    },
                )
                ingested_count += result.get("ingested", 0)
                print(f"[{course_id}] âœ… í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ì €ì¥ ì™„ë£Œ")
                if update_progress:
                    update_progress(95, "ìµœì¢… ì²˜ë¦¬ ì¤‘...")
                
            except Exception as e:
                error_msg = f"[{course_id}] âŒ í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}"
                print(error_msg)
                # í˜ë¥´ì†Œë‚˜ ì¶”ì¶œ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
        else:
            print(f"[{course_id}] âš ï¸ ì²˜ë¦¬í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        return {
            "status": "completed",
            "ingested_count": ingested_count,
            "transcript_path": transcript_path,  # STT ê²°ê³¼ íŒŒì¼ ê²½ë¡œ (ìˆëŠ” ê²½ìš°)
            "persona_profile": persona_profile_json,  # Style Analyzer ê²°ê³¼ (JSON ë¬¸ìì—´, backBê°€ DBì— ì €ì¥)
        }
        
    except Exception as e:
        error_msg = f"[{course_id}] âŒ íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì˜¤ë¥˜: {str(e)}"
        print(error_msg)
        import traceback
        traceback.print_exc()
        return {
            "status": "error",
            "ingested_count": ingested_count if 'ingested_count' in locals() else 0,
            "error": error_msg,
        }
