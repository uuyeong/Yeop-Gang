from pathlib import Path
from typing import Any, Dict, List, Optional
import tempfile
import os
import json
import shutil

from ai.config import AISettings


def _openai_client(settings: AISettings):
    from openai import OpenAI

    if not settings.openai_api_key:
        raise RuntimeError("OPENAI_API_KEY is not set")
    return OpenAI(api_key=settings.openai_api_key)


def _split_audio_file(
    audio_path: Path, max_size_mb: float = 20.0, temp_dir: Path | None = None
) -> List[Path]:
    """
    Split audio file into chunks that are under max_size_mb.
    
    Returns list of chunk file paths.
    Uses pydub which requires ffmpeg.
    """
    try:
        from pydub import AudioSegment
    except ImportError:
        raise ImportError(
            "pydub is required for audio splitting. Install with: pip install pydub"
            " Also install ffmpeg: brew install ffmpeg (macOS) or apt-get install ffmpeg (Linux)"
        )
    
    if temp_dir is None:
        temp_dir = Path(tempfile.mkdtemp())
    else:
        temp_dir.mkdir(parents=True, exist_ok=True)
    
    # Load audio file
    audio = AudioSegment.from_file(str(audio_path))
    duration_ms = len(audio)
    file_size_mb = audio_path.stat().st_size / (1024 * 1024)
    
    # Estimate duration per chunk (conservative estimate: 20MB per 10 minutes)
    # Use a safer ratio: assume 20MB = ~10 minutes of audio
    estimated_ms_per_mb = (10 * 60 * 1000) / 20  # 10 minutes in ms / 20MB
    chunk_duration_ms = int(max_size_mb * estimated_ms_per_mb * 0.9)  # 90% to be safe
    
    chunks: List[Path] = []
    chunk_index = 0
    start_ms = 0
    
    while start_ms < duration_ms:
        end_ms = min(start_ms + chunk_duration_ms, duration_ms)
        chunk_audio = audio[start_ms:end_ms]
        
        # Export chunk
        chunk_path = temp_dir / f"chunk_{chunk_index:03d}.mp3"
        chunk_audio.export(str(chunk_path), format="mp3")
        
        # Verify chunk size
        chunk_size_mb = chunk_path.stat().st_size / (1024 * 1024)
        if chunk_size_mb > max_size_mb:
            # If chunk is still too large, reduce duration and retry
            print(f"Warning: Chunk {chunk_index} is {chunk_size_mb:.2f}MB, reducing duration...")
            chunk_duration_ms = int(chunk_duration_ms * 0.7)  # Reduce by 30%
            chunk_path.unlink()  # Delete oversized chunk
            continue
        
        chunks.append(chunk_path)
        chunk_index += 1
        start_ms = end_ms
        
        print(f"Created chunk {chunk_index}: {chunk_size_mb:.2f}MB ({start_ms/1000:.1f}s - {end_ms/1000:.1f}s)")
    
    return chunks


def _transcribe_with_google(file_path: Path, settings: AISettings) -> Dict[str, Any]:
    """
    Google Cloud Speech-to-Text APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŒŒì¼ì„ ì „ì‚¬í•©ë‹ˆë‹¤.
    YouTubeì™€ ìœ ì‚¬í•œ ë†’ì€ í’ˆì§ˆì˜ ìŒì„± ì¸ì‹ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    try:
        from google.cloud import speech
        from google.oauth2 import service_account
        import io
        
        print(f"ğŸ¤ Using Google Cloud Speech-to-Text (YouTube-quality) for: {file_path.name}")
        print(f"ğŸ“¦ File size: {file_path.stat().st_size / (1024 * 1024):.2f}MB")
        
        # Google ì¸ì¦ ì„¤ì •
        credentials = None
        if settings.google_credentials_path:
            # ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ ì‚¬ìš©
            credentials_path = Path(settings.google_credentials_path)
            if credentials_path.exists():
                credentials = service_account.Credentials.from_service_account_file(
                    str(credentials_path),
                    scopes=["https://www.googleapis.com/auth/cloud-platform"]
                )
                print(f"âœ… Using service account credentials: {credentials_path}")
            else:
                print(f"âš ï¸ Credentials file not found: {credentials_path}")
        elif os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
            # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ìë™ìœ¼ë¡œ ë¡œë“œ
            print("âœ… Using GOOGLE_APPLICATION_CREDENTIALS environment variable")
        
        # Speech client ìƒì„±
        if credentials:
            client = speech.SpeechClient(credentials=credentials)
        else:
            client = speech.SpeechClient()
        
        # ì˜¤ë””ì˜¤ íŒŒì¼ ì½ê¸°
        with io.open(file_path, "rb") as audio_file:
            content = audio_file.read()
        
        # ì˜¤ë””ì˜¤ ì„¤ì • (í•œêµ­ì–´)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.ENCODING_UNSPECIFIED,  # ìë™ ê°ì§€
            sample_rate_hertz=16000,  # ì¼ë°˜ì ì¸ ìƒ˜í”Œ ë ˆì´íŠ¸
            language_code="ko-KR",  # í•œêµ­ì–´
            enable_automatic_punctuation=True,  # ìë™ êµ¬ë‘ì 
            enable_word_time_offsets=True,  # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„
            model="latest_long",  # ê¸´ ì˜¤ë””ì˜¤ì— ìµœì í™”ëœ ëª¨ë¸
        )
        
        # ì˜¤ë””ì˜¤ íŒŒì¼ì´ í¬ë©´ (10MB ì´ìƒ) long-running recognition ì‚¬ìš©
        file_size_mb = file_path.stat().st_size / (1024 * 1024)
        if file_size_mb > 10:
            print("ğŸ“¤ Using long-running recognition for large file...")
            audio = speech.RecognitionAudio(content=content)
            operation = client.long_running_recognize(config=config, audio=audio)
            print("â³ Waiting for operation to complete (this may take a while)...")
            response = operation.result(timeout=600)  # ìµœëŒ€ 10ë¶„ ëŒ€ê¸°
        else:
            print("â³ Transcribing audio file...")
            audio = speech.RecognitionAudio(content=content)
            response = client.recognize(config=config, audio=audio)
        
        # ê²°ê³¼ íŒŒì‹±
        transcript_text = ""
        segments = []
        
        for result in response.results:
            alternative = result.alternatives[0]
            transcript_text += alternative.transcript + " "
            
            # ë‹¨ì–´ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ìˆìœ¼ë©´ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±
            if alternative.words:
                segment_start = alternative.words[0].start_time.total_seconds() if alternative.words[0].start_time else 0.0
                segment_end = alternative.words[-1].end_time.total_seconds() if alternative.words[-1].end_time else 0.0
                segments.append({
                    "start": segment_start,
                    "end": segment_end,
                    "text": alternative.transcript,
                })
        
        transcript_text = transcript_text.strip()
        
        # ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ
        if not segments:
            segments = [{
                "start": 0.0,
                "end": 0.0,
                "text": transcript_text,
            }]
        
        print(f"âœ… Google STT complete: {len(transcript_text)} characters, {len(segments)} segments")
        
        return {
            "text": transcript_text,
            "segments": segments,
        }
        
    except ImportError:
        error_msg = (
            "google-cloud-speech íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
            "ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install google-cloud-speech"
        )
        print(f"âŒ {error_msg}")
        raise ImportError(error_msg)
    except Exception as e:
        import traceback
        print(f"âŒ Error in _transcribe_with_google: {type(e).__name__}: {str(e)}")
        print(f"ğŸ“‹ Traceback:")
        print(traceback.format_exc())
        raise


def _transcribe_with_openai_api(file_path: Path, settings: AISettings) -> Dict[str, Any]:
    """
    OpenAI Whisper APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ íŒŒì¼ì„ ì „ì‚¬í•©ë‹ˆë‹¤.
    ìœ ë£Œ APIì´ì§€ë§Œ ì•ˆì •ì ì´ê³  ë¹ ë¥¸ ì „ì‚¬ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
    try:
        client = _openai_client(settings)
        
        print(f"ğŸ¤ Using OpenAI Whisper API for: {file_path.name}")
        print(f"ğŸ“¦ File size: {file_path.stat().st_size / (1024 * 1024):.2f}MB")
        
        # íŒŒì¼ ì—´ê¸°
        with open(file_path, "rb") as audio_file:
            print("â³ Transcribing with OpenAI Whisper API (this may take a while for large files)...")
            
            # OpenAI Whisper API í˜¸ì¶œ
            # response_format="verbose_json"ì„ ì‚¬ìš©í•˜ë©´ íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë³´ë„ í¬í•¨ë¨
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="ko",  # í•œêµ­ì–´ ì§€ì •
                response_format="verbose_json",  # íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨ëœ JSON í˜•ì‹
            )
        
        # ê²°ê³¼ íŒŒì‹±
        # verbose_json í˜•ì‹ì€ dict ë˜ëŠ” ê°ì²´ë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆìŒ
        # OpenAI Python SDKëŠ” ë³´í†µ ê°ì²´ë¥¼ ë°˜í™˜í•˜ì§€ë§Œ, JSON íŒŒì‹± ì‹œ dictì¼ ìˆ˜ë„ ìˆìŒ
        if isinstance(transcript, dict):
            transcript_text = transcript.get("text", "")
            raw_segments = transcript.get("segments", [])
        else:
            # ê°ì²´ì¸ ê²½ìš° ì†ì„±ìœ¼ë¡œ ì ‘ê·¼
            transcript_text = getattr(transcript, "text", "") if hasattr(transcript, "text") else ""
            raw_segments = getattr(transcript, "segments", []) if hasattr(transcript, "segments") else []
        
        segments = []
        
        # segments ë°°ì—´ ì²˜ë¦¬
        if raw_segments:
            for seg in raw_segments:
                # dict ë˜ëŠ” ê°ì²´ ëª¨ë‘ ì²˜ë¦¬
                if isinstance(seg, dict):
                    start = seg.get("start", 0.0)
                    end = seg.get("end", 0.0)
                    text = seg.get("text", "")
                else:
                    # ê°ì²´ì¸ ê²½ìš°
                    start = getattr(seg, "start", 0.0) if hasattr(seg, "start") else 0.0
                    end = getattr(seg, "end", 0.0) if hasattr(seg, "end") else 0.0
                    text = getattr(seg, "text", "") if hasattr(seg, "text") else ""
                
                # íƒ€ì… ë³€í™˜ ë° ê²€ì¦
                try:
                    start = float(start) if start is not None else 0.0
                    end = float(end) if end is not None else 0.0
                except (ValueError, TypeError):
                    start = 0.0
                    end = 0.0
                
                segments.append({
                    "start": start,
                    "end": end,
                    "text": str(text) if text else "",
                })
        
        # ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ì„¸ê·¸ë¨¼íŠ¸ë¡œ
        if not segments:
            segments = [{
                "start": 0.0,
                "end": 0.0,
                "text": transcript_text if transcript_text else "",
            }]
        
        # ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ì •ë¦¬ (ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•ì‹ í¬í•¨)
        def format_time(seconds: float) -> str:
            """ì´ˆë¥¼ ë¶„:ì´ˆ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
            minutes = int(seconds // 60)
            secs = int(seconds % 60)
            return f"{minutes}:{secs:02d}"
        
        formatted_segments = []
        for seg in segments:
            start = seg.get("start", 0.0)
            end = seg.get("end", 0.0)
            formatted_segments.append({
                "start": start,
                "end": end,
                "start_formatted": format_time(start),  # ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•ì‹ (ì˜ˆ: "5:30")
                "end_formatted": format_time(end),      # ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•ì‹ (ì˜ˆ: "5:45")
                "text": seg.get("text", ""),
            })
        
        print(f"âœ… OpenAI Whisper API transcription complete: {len(transcript_text)} characters, {len(formatted_segments)} segments")
        
        # fallback segmentì—ë„ í˜•ì‹ ì¶”ê°€
        if not formatted_segments:
            formatted_segments = [{
                "start": 0.0,
                "end": 0.0,
                "start_formatted": "0:00",
                "end_formatted": "0:00",
                "text": transcript_text,
            }]
        
        return {
            "text": transcript_text,
            "segments": formatted_segments,
        }
    except ImportError:
        error_msg = (
            "openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
            "ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install openai"
        )
        print(f"âŒ {error_msg}")
        raise ImportError(error_msg)
    except Exception as e:
        import traceback
        print(f"âŒ Error in _transcribe_with_openai_api: {type(e).__name__}: {str(e)}")
        print(f"ğŸ“‹ Traceback:")
        print(traceback.format_exc())
        raise


def load_transcript_from_file(transcript_path: str) -> Optional[Dict[str, Any]]:
    """
    ì €ì¥ëœ transcript JSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        transcript_path: transcript JSON íŒŒì¼ ê²½ë¡œ
        
    Returns:
        transcript ë°ì´í„° ë˜ëŠ” None (íŒŒì¼ì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ ì‹œ)
    """
    try:
        path = Path(transcript_path)
        if not path.exists():
            return None
        
        with path.open("r", encoding="utf-8") as f:
            data = json.load(f)
        
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        if "text" in data and data["text"]:
            print(f"âœ… Loaded transcript from file: {transcript_path}")
            return {
                "text": data.get("text", ""),
                "segments": data.get("segments", []),
            }
        return None
    except Exception as e:
        print(f"âš ï¸ Failed to load transcript file {transcript_path}: {e}")
        return None


def transcribe_video(
    video_path: str, 
    settings: AISettings | None = None,
    transcript_path: Optional[str] = None,
    force_retranscribe: bool = False,
    instructor_id: Optional[str] = None,
    course_id: Optional[str] = None,
) -> Dict[str, Any]:
    """
    Transcribe a video/audio file using OpenAI Whisper.
    Automatically splits large files (>25MB) into chunks.
    
    ë§Œì•½ transcript_pathê°€ ì œê³µë˜ê³  íŒŒì¼ì´ ì¡´ì¬í•˜ë©´, STTë¥¼ ê±´ë„ˆë›°ê³  íŒŒì¼ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        video_path: ë¹„ë””ì˜¤/ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        settings: AI ì„¤ì •
        transcript_path: ì €ì¥ëœ transcript íŒŒì¼ ê²½ë¡œ (ì„ íƒì )
        force_retranscribe: Trueë©´ íŒŒì¼ì´ ìˆì–´ë„ ê°•ì œë¡œ ì¬ì „ì‚¬
        instructor_id: ê°•ì‚¬ ID (ëŒ€ì²´ ê²½ë¡œ ì°¾ê¸°ìš©, ì„ íƒì )
        course_id: ê°•ì˜ ID (ëŒ€ì²´ ê²½ë¡œ ì°¾ê¸°ìš©, ì„ íƒì )

    Returns:
        {
            "text": str,
            "segments": List[{"start": float, "end": float, "text": str}]
        }

    Fallback: if API keyê°€ ì—†ê±°ë‚˜ ì—ëŸ¬ ì‹œ placeholderë¥¼ ë°˜í™˜í•´ íŒŒì´í”„ë¼ì¸ì´ ê³„ì† ì§„í–‰ë˜ë„ë¡ í•¨.
    """
    settings = settings or AISettings()
    path = Path(video_path)
    
    # ê²½ë¡œ ì •ê·œí™” ë° í™•ì¸
    if not path.is_absolute():
        # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜ ì‹œë„
        path = path.resolve()
    
    print(f"ğŸ“ Checking file: {path}")
    print(f"ğŸ“ File exists: {path.exists()}")
    print(f"ğŸ“ Absolute path: {path.absolute()}")
    
    # íŒŒì¼ì´ ì—†ìœ¼ë©´ ëŒ€ì²´ ê²½ë¡œ ì‹œë„
    if not path.exists():
        if instructor_id and course_id:
            try:
                from core.config import AppSettings
                app_settings = AppSettings()
                potential_path = app_settings.uploads_dir / instructor_id / course_id / path.name
                if potential_path.exists():
                    path = potential_path.resolve()
                    print(f"ğŸ“ Found file at alternative path: {path}")
                else:
                    error_msg = f"Video not found: {video_path} (resolved: {path}, also tried: {potential_path})"
                    print(f"âŒ {error_msg}")
                    raise FileNotFoundError(error_msg)
            except Exception as e:
                error_msg = f"Video not found: {video_path} (resolved: {path}), error checking alternative: {e}"
                print(f"âŒ {error_msg}")
                raise FileNotFoundError(error_msg)
        else:
            error_msg = f"Video not found: {video_path} (resolved: {path})"
            print(f"âŒ {error_msg}")
            raise FileNotFoundError(error_msg)

    # ì €ì¥ëœ transcript íŒŒì¼ì´ ìˆìœ¼ë©´ ë¨¼ì € í™•ì¸
    if transcript_path and not force_retranscribe:
        loaded = load_transcript_from_file(transcript_path)
        if loaded:
            print(f"âœ… Using existing transcript file (skipping STT): {transcript_path}")
            return loaded
        else:
            print(f"âš ï¸ Transcript file not found or invalid, proceeding with STT: {transcript_path}")

    try:
        # ì˜¤ë””ì˜¤ íŒŒì¼ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, ë¹„ë””ì˜¤ íŒŒì¼(MP4 ë“±)ë§Œ MP3ë¡œ ë³€í™˜
        video_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.webm', '.flv', '.wmv'}
        audio_extensions = {'.mp3', '.wav', '.flac', '.ogg', '.m4a', '.aac'}
        
        file_ext = path.suffix.lower()
        audio_path = path
        
        # ì˜¤ë””ì˜¤ íŒŒì¼ì´ë©´ ë³€í™˜ ì—†ì´ ë°”ë¡œ ì‚¬ìš©
        if file_ext in audio_extensions:
            print(f"ğŸµ Audio file detected ({file_ext}), using directly (no conversion needed)")
        elif file_ext in video_extensions:
            print(f"ğŸ¬ Video file detected ({file_ext}), converting to MP3...")
            
            # ffmpeg ê²½ë¡œ í™•ì¸
            ffmpeg_path = shutil.which("ffmpeg")
            if not ffmpeg_path:
                possible_paths = [
                    r"C:\ffmpeg\bin\ffmpeg.exe",
                    r"C:\Program Files\ffmpeg\bin\ffmpeg.exe",
                    r"C:\Program Files (x86)\ffmpeg\bin\ffmpeg.exe",
                ]
                for p in possible_paths:
                    if Path(p).exists():
                        ffmpeg_path = p
                        break
            
            if not ffmpeg_path:
                raise RuntimeError("ffmpeg not found. Please install ffmpeg to convert video files.")
            
            # ì„ì‹œ MP3 íŒŒì¼ ìƒì„±
            temp_dir = Path(tempfile.gettempdir())
            audio_path = temp_dir / f"{path.stem}_converted.mp3"
            
            print(f"ğŸ”„ Converting {path.name} to MP3...")
            from subprocess import run
            cmd = [
                ffmpeg_path,
                "-i", str(path),
                "-vn",  # ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì œê±°
                "-acodec", "libmp3lame",  # MP3 ì½”ë±
                "-ar", "16000",  # ìƒ˜í”Œ ë ˆì´íŠ¸ 16kHz (Whisper ê¶Œì¥)
                "-ac", "1",  # ëª¨ë…¸
                "-b:a", "128k",  # ë¹„íŠ¸ë ˆì´íŠ¸
                "-y",  # ë®ì–´ì“°ê¸°
                str(audio_path)
            ]
            
            env = os.environ.copy()
            if ffmpeg_path:
                ffmpeg_dir = str(Path(ffmpeg_path).parent)
                env["PATH"] = ffmpeg_dir + os.pathsep + env.get("PATH", "")
            
            try:
                run(cmd, check=True, capture_output=True, env=env)
                print(f"âœ… Converted to MP3: {audio_path}")
            except Exception as e:
                raise RuntimeError(f"Failed to convert video to MP3: {e}")
        elif file_ext not in audio_extensions:
            print(f"âš ï¸ Unknown file format ({file_ext}), attempting direct processing...")
        
        # OpenAI Whisper API ì‚¬ìš© (ìœ ë£Œ API)
        print("âœ… Using OpenAI Whisper API")
        
        # Check file size
        file_size_mb = audio_path.stat().st_size / (1024 * 1024)
        print(f"ğŸ“ Audio file size: {file_size_mb:.2f}MB")
        
        # OpenAI Whisper APIëŠ” 25MB ì œí•œì´ ìˆìœ¼ë¯€ë¡œ í° íŒŒì¼ì€ ë¶„í•  í•„ìš”
        if file_size_mb > 25:
            print(f"âš ï¸ File size ({file_size_mb:.2f}MB) exceeds 25MB limit. Splitting into chunks...")
            chunks = _split_audio_file(audio_path, max_size_mb=20.0)
            
            all_text = ""
            all_segments = []
            offset = 0.0  # ì‹œê°„ ì˜¤í”„ì…‹
            
            def format_time(seconds: float) -> str:
                """ì´ˆë¥¼ ë¶„:ì´ˆ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
                minutes = int(seconds // 60)
                secs = int(seconds % 60)
                return f"{minutes}:{secs:02d}"
            
            for i, chunk_path in enumerate(chunks):
                print(f"ğŸ“¤ Transcribing chunk {i+1}/{len(chunks)}...")
                try:
                    chunk_result = _transcribe_with_openai_api(chunk_path, settings)
                    
                    # ì„¸ê·¸ë¨¼íŠ¸ ì‹œê°„ ì˜¤í”„ì…‹ ì ìš©
                    for seg in chunk_result.get("segments", []):
                        seg["start"] = float(seg.get("start", 0.0)) + offset
                        seg["end"] = float(seg.get("end", 0.0)) + offset
                        # ì‹œê°„ í¬ë§· ì¬ê³„ì‚°
                        seg["start_formatted"] = format_time(seg["start"])
                        seg["end_formatted"] = format_time(seg["end"])
                    
                    all_text += chunk_result.get("text", "") + " "
                    all_segments.extend(chunk_result.get("segments", []))
                    
                    # ë‹¤ìŒ ì²­í¬ì˜ ì˜¤í”„ì…‹ ê³„ì‚° (ë§ˆì§€ë§‰ ì„¸ê·¸ë¨¼íŠ¸ì˜ ë ì‹œê°„)
                    if chunk_result.get("segments"):
                        offset = float(chunk_result["segments"][-1].get("end", 0.0))
                except Exception as e:
                    print(f"âš ï¸ Error transcribing chunk {i+1}: {e}")
                    import traceback
                    print(traceback.format_exc())
                    # ì²­í¬ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                    continue
                finally:
                    # ì„ì‹œ ì²­í¬ íŒŒì¼ ì‚­ì œ
                    try:
                        if chunk_path.exists():
                            chunk_path.unlink()
                    except Exception:
                        pass
            
            result = {
                "text": all_text.strip(),
                "segments": all_segments,
            }
        else:
            # 25MB ì´í•˜ë©´ ì§ì ‘ ì „ì‚¬
            print("ğŸ¤ Transcribing with OpenAI Whisper API...")
            result = _transcribe_with_openai_api(audio_path, settings)
        
        print(f"âœ… STT success: transcribed text length: {len(result['text'])}")
        
        # ì„ì‹œ ë³€í™˜ íŒŒì¼ ì‚­ì œ
        if file_ext in video_extensions and audio_path.exists() and audio_path != path:
            try:
                audio_path.unlink()
                print(f"ğŸ—‘ï¸ Cleaned up temporary MP3 file")
            except Exception:
                pass
        
        return result
        
    except ImportError as e:
        # openai íŒ¨í‚¤ì§€ê°€ ì—†ëŠ” ê²½ìš°
        error_msg = str(e)
        error_type = type(e).__name__
        print(f"âŒ STT ERROR [{error_type}]: {error_msg}")
        print("ğŸ’¡ Please install openai: pip install openai")
        print("ğŸ’¡ Also make sure OPENAI_API_KEY is set in your environment")
        # ì—ëŸ¬ ë°œìƒ - ì €ì¥í•˜ì§€ ì•ŠìŒ
        raise
    except Exception as e:
        # Log the actual error for debugging
        import traceback
        error_msg = str(e)
        error_type = type(e).__name__
        print(f"âŒ STT ERROR [{error_type}]: {error_msg}")
        print(f"ğŸ“‹ Full traceback:")
        print(traceback.format_exc())
        
        print(f"âš ï¸ OpenAI Whisper API STT failed. Possible causes:")
        print(f"   - openai package not installed: pip install openai")
        print(f"   - OPENAI_API_KEY not set or invalid")
        print(f"   - File format not supported")
        print(f"   - File size exceeds 25MB (will be split automatically)")
        print(f"   - API rate limit or quota exceeded")
        
        # ì—ëŸ¬ ë°œìƒ - ì €ì¥í•˜ì§€ ì•ŠìŒ
        raise
