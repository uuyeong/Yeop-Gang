"""
ê°œì„ ëœ ë¹„ë™ê¸° Task ê´€ë¦¬
- ë°±ì—”ë“œ Aì˜ processor.process_course_assets() í˜¸ì¶œ
- ì§„í–‰ë¥  ì¶”ì 
- ì—ëŸ¬ í•¸ë“¤ë§
"""
import logging
from pathlib import Path
from typing import Optional, List
from datetime import datetime

from fastapi import BackgroundTasks
from sqlmodel import Session, select

from core.db import engine
from core.models import Course, CourseStatus, Video

logger = logging.getLogger(__name__)


def _split_text_into_chunks(text: str, model_name: str, max_tokens: int = 7000) -> List[str]:
    """
    í…ìŠ¤íŠ¸ë¥¼ í† í° ê¸¸ì´ ê¸°ì¤€ìœ¼ë¡œ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    embedding ëª¨ë¸ì˜ ìµœëŒ€ í† í° ê¸¸ì´ ì œí•œì„ ê³ ë ¤í•˜ì—¬ ì•ˆì „í•˜ê²Œ ë¶„í• í•©ë‹ˆë‹¤.
    
    Args:
        text: ë¶„í• í•  í…ìŠ¤íŠ¸
        model_name: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ (tiktoken ì¸ì½”ë”©ìš©)
        max_tokens: ê° ì²­í¬ì˜ ìµœëŒ€ í† í° ìˆ˜ (ê¸°ë³¸ê°’: 7000, ì•ˆì „ ë§ˆì§„ í¬í•¨)
    
    Returns:
        í…ìŠ¤íŠ¸ ì²­í¬ ë¦¬ìŠ¤íŠ¸
    """
    try:
        import tiktoken
    except ImportError:
        logger.warning("tiktoken not available, using character-based chunking")
        # tiktokenì´ ì—†ìœ¼ë©´ ë¬¸ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë¶„í•  (1 í† í° â‰ˆ 4 ë¬¸ì ê°€ì •)
        chunk_size = max_tokens * 4
        chunks = []
        for i in range(0, len(text), chunk_size):
            chunks.append(text[i:i + chunk_size])
        return chunks
    
    try:
        # ëª¨ë¸ì— ë§ëŠ” ì¸ì½”ë” ê°€ì ¸ì˜¤ê¸°
        encoding = tiktoken.encoding_for_model(model_name)
    except KeyError:
        # ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ cl100k_base (GPT-4/GPT-3.5ìš©) ì‚¬ìš©
        encoding = tiktoken.get_encoding("cl100k_base")
        logger.warning(f"Encoding for model {model_name} not found, using cl100k_base")
    
    # í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ì¸ì½”ë”©
    tokens = encoding.encode(text)
    
    if len(tokens) <= max_tokens:
        # í† í° ìˆ˜ê°€ ì œí•œ ì´í•˜ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        return [text]
    
    # í† í°ì„ ì²­í¬ë¡œ ë¶„í• 
    chunks = []
    for i in range(0, len(tokens), max_tokens):
        chunk_tokens = tokens[i:i + max_tokens]
        chunk_text = encoding.decode(chunk_tokens)
        chunks.append(chunk_text)
    
    logger.info(f"Split text into {len(chunks)} chunks (total tokens: {len(tokens)}, max per chunk: {max_tokens})")
    return chunks


def enqueue_processing_task(
    tasks: BackgroundTasks,
    *,
    course_id: str,
    instructor_id: str,
    video_path: Optional[Path] = None,
    audio_path: Optional[Path] = None,
    pdf_path: Optional[Path] = None,
    smi_path: Optional[Path] = None,
) -> None:
    """
    ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì‘ì—… ë“±ë¡
    ë°±ì—”ë“œ Aì˜ processor.process_course_assets()ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    """
    tasks.add_task(
        process_course_assets_wrapper,
        course_id=course_id,
        instructor_id=instructor_id,
        video_path=video_path,
        audio_path=audio_path,
        pdf_path=pdf_path,
        smi_path=smi_path,
    )


def process_course_assets_wrapper(
    *,
    course_id: str,
    instructor_id: str,
    video_path: Optional[Path] = None,
    audio_path: Optional[Path] = None,
    pdf_path: Optional[Path] = None,
    smi_path: Optional[Path] = None,
) -> None:
    """
    ë°±ì—”ë“œ Aì˜ processor.process_course_assets()ë¥¼ í˜¸ì¶œí•˜ëŠ” ë˜í¼ í•¨ìˆ˜
    ë°±ì—”ë“œ BëŠ” ì´ í•¨ìˆ˜ë¥¼ í†µí•´ ë°±ì—”ë“œ Aì˜ ì²˜ë¦¬ ë¡œì§ì„ í˜¸ì¶œí•©ë‹ˆë‹¤.
    """
    try:
        # ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        if video_path:
            video_path = Path(video_path).resolve()
            logger.info(f"ğŸ“ Video path resolved: {video_path} (exists: {video_path.exists()})")
        if audio_path:
            audio_path = Path(audio_path).resolve()
            logger.info(f"ğŸ“ Audio path resolved: {audio_path} (exists: {audio_path.exists()})")
        if pdf_path:
            pdf_path = Path(pdf_path).resolve()
            logger.info(f"ğŸ“ PDF path resolved: {pdf_path} (exists: {pdf_path.exists()})")
        if smi_path:
            smi_path = Path(smi_path).resolve()
            logger.info(f"ğŸ“ SMI path resolved: {smi_path} (exists: {smi_path.exists()})")
        
        # ì§„í–‰ë„ ì´ˆê¸°í™”
        _update_progress(course_id, 0, "ì²˜ë¦¬ ì‹œì‘")
        
        # ë°±ì—”ë“œ Aì˜ processor ëª¨ë“ˆ import ì‹œë„
        try:
            from ai.pipelines.processor import process_course_assets
            from core.models import Instructor
            
            # ê°•ì‚¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            instructor_info = None
            with Session(engine) as session:
                instructor = session.get(Instructor, instructor_id)
                if instructor:
                    instructor_info = {
                        "name": instructor.name,
                        "bio": instructor.bio,
                        "specialization": instructor.specialization,
                    }
                    logger.info(f"ê°•ì‚¬ ì •ë³´ ë¡œë“œ: {instructor_id} - {instructor.name}")
            
            # ë°±ì—”ë“œ Aì˜ í•¨ìˆ˜ê°€ ìˆìœ¼ë©´ í˜¸ì¶œ
            _update_progress(course_id, 10, "íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            
            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ ì½œë°± í•¨ìˆ˜ ìƒì„±
            def update_progress_callback(progress: int, message: str) -> None:
                _update_progress(course_id, progress, message)
            
            result = process_course_assets(
                course_id=course_id,
                instructor_id=instructor_id,
                video_path=video_path,
                audio_path=audio_path,
                pdf_path=pdf_path,
                smi_path=smi_path,
                update_progress=update_progress_callback,
                instructor_info=instructor_info,
            )
            
            # ì²˜ë¦¬ ê²°ê³¼ í™•ì¸
            if result.get("status") == "completed":
                ingested_count = result.get("ingested_count", 0)
                transcript_path = result.get("transcript_path")  # STT ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
                logger.info(f"Course {course_id} processed successfully via backend A processor (ingested: {ingested_count})")
                _update_progress(course_id, 100, f"ì²˜ë¦¬ ì™„ë£Œ (ì¸ì œìŠ¤íŠ¸: {ingested_count}ê°œ)")
                
                # DB ìƒíƒœë¥¼ completedë¡œ ì—…ë°ì´íŠ¸ ë° transcript_path ì €ì¥
                with Session(engine) as session:
                    course = session.get(Course, course_id)
                    if course:
                        course.status = CourseStatus.completed
                        course.error_message = None
                        course.progress = 100
                        session.commit()
                    
                    # Video/Audio ë ˆì½”ë“œì— transcript_path ì €ì¥
                    if transcript_path:
                        # video_path ë˜ëŠ” audio_path ì¤‘ ì²˜ë¦¬ëœ ê²ƒ ì°¾ê¸°
                        target_path = video_path or audio_path
                        if target_path:
                            videos = session.exec(
                                select(Video).where(
                                    Video.course_id == course_id,
                                    Video.filename == target_path.name
                                )
                            ).all()
                            for vid in videos:
                                vid.transcript_path = transcript_path
                            session.commit()
                            logger.info(f"Transcript path saved to Video record: {transcript_path}")
            else:
                # ì²˜ë¦¬ ì‹¤íŒ¨
                error_msg = result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                logger.error(f"Course {course_id} processing failed: {error_msg}")
                _update_progress(course_id, 0, f"ì²˜ë¦¬ ì‹¤íŒ¨: {error_msg}")
                
                # DB ìƒíƒœë¥¼ failedë¡œ ì—…ë°ì´íŠ¸
                with Session(engine) as session:
                    course = session.get(Course, course_id)
                    if course:
                        course.status = CourseStatus.failed
                        course.error_message = error_msg
                        session.commit()
                        
        except ImportError:
            # ë°±ì—”ë“œ Aì˜ processor.pyê°€ ì•„ì§ ì—†ìœ¼ë©´ ê¸°ì¡´ ë¡œì§ ì‚¬ìš© (ì„ì‹œ)
            logger.warning(
                "Backend A processor.py not found. Using fallback processing. "
                "This should be replaced when processor.py is implemented."
            )
            _fallback_process_course_assets(
                course_id=course_id,
                instructor_id=instructor_id,
                video_path=video_path,
                audio_path=audio_path,
                pdf_path=pdf_path,
                smi_path=smi_path,
            )
    except Exception as e:
        error_msg = str(e)
        logger.error(f"Error processing course {course_id}: {error_msg}", exc_info=True)
        _update_progress(course_id, 0, f"ì˜¤ë¥˜ ë°œìƒ: {error_msg}")
        # DBì— ì‹¤íŒ¨ ìƒíƒœ ì €ì¥
        
        with Session(engine) as session:
            course = session.get(Course, course_id)
            if course:
                course.status = CourseStatus.failed
                course.error_message = error_msg
                session.commit()
                logger.error(f"Course {course_id} marked as failed. Error: {error_msg}")


def _update_progress(course_id: str, progress: int, message: Optional[str] = None) -> None:
    """
    ì§„í–‰ë„ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    
    Args:
        course_id: ê°•ì˜ ID
        progress: ì§„í–‰ë„ (0-100)
        message: ì§„í–‰ ìƒí™© ë©”ì‹œì§€ (ì˜µì…˜)
    """
    from sqlmodel import Session
    from core.models import Course
    
    with Session(engine) as session:
        course = session.get(Course, course_id)
        if course:
            course.progress = max(0, min(100, progress))  # 0-100 ë²”ìœ„ë¡œ ì œí•œ
            session.commit()
            if message:
                logger.info(f"Progress updated for course {course_id}: {progress}% - {message}")
            else:
                logger.info(f"Progress updated for course {course_id}: {progress}%")


def _fallback_process_course_assets(
    *,
    course_id: str,
    instructor_id: str,
    video_path: Optional[Path] = None,
    audio_path: Optional[Path] = None,
    pdf_path: Optional[Path] = None,
    smi_path: Optional[Path] = None,
) -> None:
    """
    í´ë°± ì²˜ë¦¬ í•¨ìˆ˜ - ì‹¤ì œ STT, ì„ë² ë”©, í˜ë¥´ì†Œë‚˜ ìƒì„± ìˆ˜í–‰
    ë°±ì—”ë“œ Aì˜ processor.pyê°€ ì—†ì„ ë•Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ì´ í•¨ìˆ˜ê°€ ì‹¤í–‰ë˜ì–´ ì²˜ë¦¬ë©ë‹ˆë‹¤.
    """
    from sqlmodel import Session
    from core.models import Course, CourseStatus, Video
    from ai.config import AISettings
    from ai.pipelines.rag import RAGPipeline
    from ai.services.stt import transcribe_video
    
    try:
        # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if video_path:
            video_path = Path(video_path).resolve()
            if not video_path.exists():
                error_msg = f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}"
                logger.error(f"âŒ {error_msg}")
                raise FileNotFoundError(error_msg)
        
        if audio_path:
            audio_path = Path(audio_path).resolve()
            if not audio_path.exists():
                error_msg = f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path}"
                logger.error(f"âŒ {error_msg}")
                raise FileNotFoundError(error_msg)
        
        if pdf_path:
            pdf_path = Path(pdf_path).resolve()
            if not pdf_path.exists():
                error_msg = f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}"
                logger.error(f"âŒ {error_msg}")
                raise FileNotFoundError(error_msg)
        
        if smi_path:
            smi_path = Path(smi_path).resolve()
            if not smi_path.exists():
                error_msg = f"SMI íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {smi_path}"
                logger.error(f"âŒ {error_msg}")
                raise FileNotFoundError(error_msg)
        
        # ì²˜ë¦¬í•  íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        if not video_path and not audio_path and not pdf_path and not smi_path:
            error_msg = "ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¹„ë””ì˜¤, ì˜¤ë””ì˜¤, PDF ë˜ëŠ” SMI íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
            logger.error(f"âŒ {error_msg}")
            raise ValueError(error_msg)
        
        settings = AISettings()
        
        # OPENAI_API_KEY í™•ì¸ (STTëŠ” ë¡œì»¬ Whisper ì‚¬ìš©í•˜ë¯€ë¡œ í•„ìˆ˜ëŠ” ì•„ë‹ˆì§€ë§Œ, í˜ë¥´ì†Œë‚˜ ìƒì„±ì—ëŠ” í•„ìš”)
        if not settings.openai_api_key:
            logger.warning("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í˜ë¥´ì†Œë‚˜ ìƒì„±ì´ ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        pipeline = RAGPipeline(settings)
        
        with Session(engine) as session:
            course = session.get(Course, course_id)
            if not course:
                course = Course(id=course_id, instructor_id=instructor_id)
                session.add(course)
            course.status = CourseStatus.processing
            course.progress = 0
            course.error_message = None
            session.commit()
            
            logger.info(f"Starting processing for course {course_id}")
            texts: list[str] = []
        
        # SMI ìë§‰ íŒŒì¼ì´ ìˆìœ¼ë©´ STT ê±´ë„ˆë›°ê³  SMI íŒŒì‹±
        if smi_path:
            try:
                logger.info(f"ğŸ“ SMI subtitle file detected: {smi_path}")
                _update_progress(course_id, 10, "SMI ìë§‰ íŒŒì¼ íŒŒì‹± ì¤‘...")
                
                from ai.services.smi_parser import parse_smi_file
                import json
                
                # SMI íŒŒì¼ íŒŒì‹±
                transcript_result = parse_smi_file(smi_path)
                transcript_text = transcript_result.get("text", "")
                segments = transcript_result.get("segments", [])
                
                logger.info(f"âœ… SMI parsed: {len(transcript_text)} chars, {len(segments)} segments")
                
                # Transcript JSON ì €ì¥
                from core.config import AppSettings
                app_settings = AppSettings()
                course_dir = app_settings.uploads_dir / instructor_id / course_id
                course_dir.mkdir(parents=True, exist_ok=True)
                
                transcript_filename = f"transcript_{smi_path.stem}.json"
                transcript_file_path = course_dir / transcript_filename
                
                transcript_data = {
                    "text": transcript_text,
                    "segments": segments,
                    "source_file": smi_path.name,
                    "course_id": course_id,
                    "instructor_id": instructor_id,
                }
                
                with transcript_file_path.open("w", encoding="utf-8") as f:
                    json.dump(transcript_data, f, ensure_ascii=False, indent=2)
                
                logger.info(f"âœ… Transcript JSON saved: {transcript_file_path}")
                
                _update_progress(course_id, 40, "SMI ìë§‰ íŒŒì¼ íŒŒì‹± ì™„ë£Œ")
                
                # ì„ë² ë”© ì²˜ë¦¬ë¡œ ì§„í–‰
                if transcript_text:
                    texts.append(transcript_text)
                    
                    # ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”©
                    _update_progress(course_id, 50, "ìë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì¤‘...")
                    for i, seg in enumerate(segments):
                        seg_text = seg.get("text", "")
                        if seg_text:
                            pipeline.ingest_text(
                                seg_text,
                                course_id=course_id,
                                metadata={
                                    "type": "audio_segment",
                                    "start": seg.get("start", 0.0),
                                    "end": seg.get("end", 0.0),
                                    "start_formatted": seg.get("start_formatted", ""),
                                    "end_formatted": seg.get("end_formatted", ""),
                                }
                            )
                    _update_progress(course_id, 60, "ìë§‰ ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì™„ë£Œ")
                
            except Exception as e:
                error_msg = f"SMI íŒŒì¼ íŒŒì‹± ì‹¤íŒ¨: {str(e)}"
                logger.error(f"âŒ {error_msg}")
                import traceback
                logger.error(traceback.format_exc())
                # DBì— ì‹¤íŒ¨ ìƒíƒœ ì €ì¥
                with Session(engine) as session:
                    course = session.get(Course, course_id)
                    if course:
                        course.status = CourseStatus.failed
                        course.error_message = error_msg
                        session.commit()
                raise Exception(error_msg)
        
        # ì˜¤ë””ì˜¤ íŒŒì¼ ìš°ì„  ì²˜ë¦¬ (MP3 ë“±), ì—†ìœ¼ë©´ ë¹„ë””ì˜¤ ì²˜ë¦¬
        elif audio_path:
            try:
                # íŒŒì¼ ê²½ë¡œ í™•ì¸ ë° ì •ê·œí™”
                if not isinstance(audio_path, Path):
                    audio_path = Path(audio_path)
                
                # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                if not audio_path.is_absolute():
                    audio_path = audio_path.resolve()
                
                logger.info(f"ğŸ“ Audio file path: {audio_path}")
                logger.info(f"ğŸ“ Audio file exists: {audio_path.exists()}")
                
                if not audio_path.exists():
                    # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒëŒ€ ê²½ë¡œë¡œë„ ì‹œë„
                    from core.config import AppSettings
                    app_settings = AppSettings()
                    potential_path = app_settings.uploads_dir / instructor_id / course_id / audio_path.name
                    if potential_path.exists():
                        audio_path = potential_path.resolve()
                        logger.info(f"ğŸ“ Found audio file at alternative path: {audio_path}")
                    else:
                        error_msg = f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path} (also tried: {potential_path})"
                        logger.error(f"âŒ {error_msg}")
                        raise FileNotFoundError(error_msg)
                
                logger.info(f"ğŸ¤ Starting STT for audio: {audio_path}")
                _update_progress(course_id, 10, "ì˜¤ë””ì˜¤ ìŒì„± ì¸ì‹(STT) ì‹œì‘ (ë¬´ë£Œ ë¡œì»¬ Whisper ì‚¬ìš©)")
                
                # ë¡œì»¬ Whisper ì‚¬ìš© (ë¬´ë£Œ, API í‚¤ ë¶ˆí•„ìš”)
                logger.info(f"âœ… Using local Whisper (FREE, no API key needed)")
                
                # ì²« ì—…ë¡œë“œì´ë¯€ë¡œ ë¬´ì¡°ê±´ STT ì‹¤í–‰
                logger.info(f"ğŸ”„ Running STT (force_retranscribe=True to ensure fresh transcription)...")
                transcript_result = transcribe_video(
                    str(audio_path), 
                    settings=settings,
                    transcript_path=None,  # ê¸°ì¡´ íŒŒì¼ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ìƒì„±
                    force_retranscribe=True,  # ê°•ì œë¡œ STT ì‹¤í–‰
                    instructor_id=instructor_id,
                    course_id=course_id,
                )
                _update_progress(course_id, 40, "ì˜¤ë””ì˜¤ ìŒì„± ì¸ì‹(STT) ì™„ë£Œ")
                transcript_text = transcript_result.get("text", "")
                segments = transcript_result.get("segments", [])
                
                logger.info(f"ğŸ“ STT result - text length: {len(transcript_text)}, segments: {len(segments)}")
                
                # STT ì‹¤íŒ¨ ì²´í¬ - placeholderë‚˜ ì—ëŸ¬ ë©”ì‹œì§€ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ
                transcript_lower = transcript_text.lower()
                if ("placeholder" in transcript_lower or 
                    "transcription failed" in transcript_lower or
                    "error" in transcript_lower and "failed" in transcript_lower):
                    error_msg = f"ì˜¤ë””ì˜¤ STTê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {transcript_text[:100]}"
                    logger.error(f"âŒ {error_msg}")
                    raise ValueError(error_msg)
                
                if not transcript_text or not transcript_text.strip():
                    error_msg = f"ì˜¤ë””ì˜¤ STT ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
                    logger.error(f"âŒ {error_msg}")
                    raise ValueError(error_msg)
                
                # STT ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
                transcript_path = None
                if transcript_text:
                    try:
                        from core.config import AppSettings
                        import json
                        
                        app_settings = AppSettings()
                        course_dir = app_settings.uploads_dir / instructor_id / course_id
                        course_dir.mkdir(parents=True, exist_ok=True)
                        
                        # transcript íŒŒì¼ëª…: transcript_{ì›ë³¸íŒŒì¼ëª…}.json
                        transcript_filename = f"transcript_{audio_path.stem}.json"
                        transcript_file_path = course_dir / transcript_filename
                        
                        # JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ì „ì²´ í…ìŠ¤íŠ¸ + ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´)
                        transcript_data = {
                            "text": transcript_text,
                            "segments": segments,
                            "source_file": audio_path.name,
                            "course_id": course_id,
                            "instructor_id": instructor_id,
                        }
                        
                        logger.info(f"Attempting to save transcript to: {transcript_file_path}")
                        logger.info(f"Transcript text length: {len(transcript_text)}")
                        
                        with transcript_file_path.open("w", encoding="utf-8") as f:
                            json.dump(transcript_data, f, ensure_ascii=False, indent=2)
                        
                        # íŒŒì¼ì´ ì‹¤ì œë¡œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
                        if transcript_file_path.exists():
                            file_size = transcript_file_path.stat().st_size
                            transcript_path = str(transcript_file_path)
                            logger.info(f"âœ… STT transcript JSON saved successfully: {transcript_path} (size: {file_size} bytes)")
                        else:
                            logger.error(f"âŒ Transcript file was not created: {transcript_file_path}")
                    except Exception as e:
                        import traceback
                        logger.error(f"âŒ Failed to save transcript file: {e}")
                        logger.error(f"Error details: {traceback.format_exc()}")
                        # íŒŒì¼ ì €ì¥ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                
                if transcript_text:
                    # ì „ì²´ í…ìŠ¤íŠ¸ ì €ì¥
                    texts.append(transcript_text)
                    
                    # ì„¸ê·¸ë¨¼íŠ¸ë³„ë¡œ ì„ë² ë”© ë° ë²¡í„° DB ì €ì¥ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
                    logger.info(f"Processing {len(segments)} audio segments for embedding")
                    segment_texts = []
                    for seg in segments:
                        seg_text = seg.get("text", "").strip()
                        if seg_text:
                            start_time = seg.get("start", 0.0)
                            segment_texts.append(seg_text)
                    
                    if segment_texts:
                        _update_progress(course_id, 50, "ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘")
                        ingested = pipeline.ingest_texts(
                            segment_texts,
                            course_id=course_id,
                            metadata={"source": "audio", "filename": audio_path.name}
                        )
                        ingested_count = ingested.get("ingested_count", 0)
                        _update_progress(course_id, 60, "ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì™„ë£Œ")
                        logger.info(f"âœ… Ingested {ingested_count} audio segments into vector DB")
                
                # Audio ë ˆì½”ë“œ ìƒì„±
                absolute_path = audio_path.resolve()
                vid = Video(
                    course_id=course_id,
                    filename=audio_path.name,
                    storage_path=str(absolute_path),
                    filetype="audio",
                    transcript_path=transcript_path,
                )
                session.add(vid)
                session.commit()
                logger.info(f"Audio record created: {audio_path.name}, transcript_path: {transcript_path}")
                
            except (FileNotFoundError, ValueError) as e:
                error_msg = f"ì˜¤ë””ì˜¤ STT ì²˜ë¦¬ ì˜¤ë¥˜ ({audio_path.name if audio_path else 'unknown'}): {str(e)}"
                logger.error(f"âŒ {error_msg}")
                import traceback
                logger.error(traceback.format_exc())
                with Session(engine) as session:
                    course = session.get(Course, course_id)
                    if course:
                        course.status = CourseStatus.failed
                        course.progress = 0
                        course.error_message = error_msg
                        session.commit()
                raise Exception(error_msg)
            except Exception as e:
                error_msg = f"ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}"
                logger.error(f"âŒ {error_msg}")
                import traceback
                logger.error(traceback.format_exc())
                with Session(engine) as session:
                    course = session.get(Course, course_id)
                    if course:
                        course.status = CourseStatus.failed
                        course.progress = 0
                        course.error_message = error_msg
                        session.commit()
                raise Exception(error_msg)
        
        # ë¹„ë””ì˜¤ ì²˜ë¦¬ (STT) - ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ì„ ë•Œë§Œ
        elif video_path:
            try:
                # íŒŒì¼ ê²½ë¡œ í™•ì¸ ë° ì •ê·œí™”
                video_path = Path(video_path).resolve()
                logger.info(f"ğŸ“ Video file path: {video_path}")
                logger.info(f"ğŸ“ Video file exists: {video_path.exists()}")
                logger.info(f"ğŸ“ Video file absolute path: {video_path.absolute()}")
                
                if not video_path.exists():
                    error_msg = f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}"
                    logger.error(f"âŒ {error_msg}")
                    raise FileNotFoundError(error_msg)
                
                logger.info(f"ğŸ¤ Starting STT for video: {video_path}")
                _update_progress(course_id, 10, "ìŒì„± ì¸ì‹(STT) ì‹œì‘ (ë¬´ë£Œ ë¡œì»¬ Whisper ì‚¬ìš©)")
                
                # ë¡œì»¬ Whisper ì‚¬ìš© (ë¬´ë£Œ, API í‚¤ ë¶ˆí•„ìš”)
                logger.info(f"âœ… Using local Whisper (FREE, no API key needed)")
                
                # ì²« ì—…ë¡œë“œì´ë¯€ë¡œ ë¬´ì¡°ê±´ STT ì‹¤í–‰ (force_retranscribe=True)
                # ê¸°ì¡´ transcript íŒŒì¼ì´ ìˆì–´ë„ ì¬ìƒì„± (í•œ ë²ˆë§Œ ì‹¤í–‰ë˜ë„ë¡ ë³´ì¥)
                logger.info(f"ğŸ”„ Running STT (force_retranscribe=True to ensure fresh transcription)...")
                transcript_result = transcribe_video(
                    str(video_path), 
                    settings=settings,
                    transcript_path=None,  # ê¸°ì¡´ íŒŒì¼ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ìƒì„±
                    force_retranscribe=True,  # ê°•ì œë¡œ STT ì‹¤í–‰
                    instructor_id=instructor_id,
                    course_id=course_id,
                )
                _update_progress(course_id, 40, "ìŒì„± ì¸ì‹(STT) ì™„ë£Œ")
                transcript_text = transcript_result.get("text", "")
                segments = transcript_result.get("segments", [])
                
                logger.info(f"ğŸ“ STT result - text length: {len(transcript_text)}, segments: {len(segments)}")
                
                # STT ì‹¤íŒ¨ ì²´í¬ - placeholderë‚˜ ì—ëŸ¬ ë©”ì‹œì§€ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ
                transcript_lower = transcript_text.lower()
                if ("placeholder" in transcript_lower or 
                    "transcription failed" in transcript_lower or
                    "failed:" in transcript_lower or
                    "error" in transcript_lower):
                    error_msg = (
                        f"âŒ STTê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. "
                        f"ë°˜í™˜ëœ ë©”ì‹œì§€: {transcript_text[:200]}... "
                        f"ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”."
                    )
                    logger.error(error_msg)
                    raise ValueError(error_msg)
                
                if not transcript_text or not transcript_text.strip():
                    error_msg = "STT ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”."
                    logger.error(f"âŒ {error_msg}")
                    raise ValueError(error_msg)
                
                logger.info(f"âœ… STT ì„±ê³µ! ì „ì‚¬ëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(transcript_text)} ë¬¸ì")
                
                # STT ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
                transcript_path = None
                if transcript_text:
                    try:
                        from core.config import AppSettings
                        import json
                        
                        app_settings = AppSettings()
                        course_dir = app_settings.uploads_dir / instructor_id / course_id
                        course_dir.mkdir(parents=True, exist_ok=True)
                        
                        # transcript íŒŒì¼ëª…: transcript_{ì›ë³¸íŒŒì¼ëª…}.json
                        transcript_filename = f"transcript_{video_path.stem}.json"
                        transcript_file_path = course_dir / transcript_filename
                        
                        # JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ì „ì²´ í…ìŠ¤íŠ¸ + ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´)
                        transcript_data = {
                            "text": transcript_text,
                            "segments": segments,
                            "source_file": video_path.name,
                            "course_id": course_id,
                            "instructor_id": instructor_id,
                        }
                        
                        logger.info(f"Attempting to save transcript to: {transcript_file_path}")
                        logger.info(f"Transcript text length: {len(transcript_text)}")
                        
                        with transcript_file_path.open("w", encoding="utf-8") as f:
                            json.dump(transcript_data, f, ensure_ascii=False, indent=2)
                        
                        # íŒŒì¼ì´ ì‹¤ì œë¡œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
                        if transcript_file_path.exists():
                            file_size = transcript_file_path.stat().st_size
                            transcript_path = str(transcript_file_path)
                            logger.info(f"âœ… STT transcript JSON saved successfully: {transcript_path} (size: {file_size} bytes)")
                        else:
                            logger.error(f"âŒ Transcript file was not created: {transcript_file_path}")
                    except Exception as e:
                        import traceback
                        logger.error(f"âŒ Failed to save transcript file: {e}")
                        logger.error(f"Error details: {traceback.format_exc()}")
                        # íŒŒì¼ ì €ì¥ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                
                if transcript_text:
                    # ì „ì²´ í…ìŠ¤íŠ¸ ì €ì¥
                    texts.append(transcript_text)
                    
                    # ì„¸ê·¸ë¨¼íŠ¸ë³„ë¡œ ì„ë² ë”© ë° ë²¡í„° DB ì €ì¥ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
                    logger.info(f"Processing {len(segments)} segments for embedding")
                    segment_texts = []
                    segment_metas = []
                    for idx, seg in enumerate(segments):
                        seg_text = seg.get("text", "")
                        if not seg_text:
                            continue
                        seg_meta = {
                            "course_id": course_id,
                            "instructor_id": instructor_id,
                            "source": video_path.name,
                            "start_time": seg.get("start"),
                            "end_time": seg.get("end"),
                            "segment_index": idx,
                            "type": "segment",
                        }
                        segment_texts.append(seg_text)
                        segment_metas.append(seg_meta)
                    
                    # ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ í•œ ë²ˆì— ì €ì¥ (ê³ ìœ  ID ë³´ì¥)
                    if segment_texts:
                        from ai.services.embeddings import embed_texts
                        from ai.services.vectorstore import get_chroma_client, get_collection
                        
                        _update_progress(course_id, 50, "ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘")
                        embeddings = embed_texts(segment_texts, settings)
                        client = get_chroma_client(settings)
                        collection = get_collection(client, settings)
                        
                        # ê³ ìœ  ID ìƒì„±: course_id-segment-{index}
                        segment_ids = [f"{course_id}-segment-{i}" for i in range(len(segment_texts))]
                        
                        collection.upsert(
                            ids=segment_ids,
                            documents=segment_texts,
                            metadatas=segment_metas,
                            embeddings=embeddings,
                        )
                        _update_progress(course_id, 60, "ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì™„ë£Œ")
                        logger.info(f"Stored {len(segment_texts)} segments to vector DB")
                
                # Video/Audio ë ˆì½”ë“œ ìƒì„± (íŒŒì¼ í™•ì¥ìë¡œ íƒ€ì… íŒë‹¨)
                file_ext = video_path.suffix.lower()
                if file_ext in [".mp3", ".wav", ".m4a", ".aac", ".ogg", ".flac"]:
                    file_type = "audio"
                elif file_ext in [".mp4", ".avi", ".mov", ".mkv", ".webm"]:
                    file_type = "video"
                else:
                    file_type = "video"  # ê¸°ë³¸ê°’
                
                # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
                absolute_path = video_path.resolve()
                vid = Video(
                    course_id=course_id,
                    filename=video_path.name,
                    storage_path=str(absolute_path),
                    filetype=file_type,
                    transcript_path=transcript_path,  # STT ê²°ê³¼ íŒŒì¼ ê²½ë¡œ ì €ì¥
                )
                session.add(vid)
                session.commit()
                logger.info(f"Video record created: {video_path.name}, transcript_path: {transcript_path}")
                
            except FileNotFoundError as e:
                error_msg = f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}"
                logger.error(f"Video processing error: {error_msg}", exc_info=True)
                with Session(engine) as session:
                    course = session.get(Course, course_id)
                    if course:
                        course.status = CourseStatus.failed
                        course.error_message = error_msg
                        session.commit()
                raise Exception(error_msg)
            except ValueError as e:
                error_msg = str(e)
                logger.error(f"Video processing error: {error_msg}", exc_info=True)
                with Session(engine) as session:
                    course = session.get(Course, course_id)
                    if course:
                        course.status = CourseStatus.failed
                        course.error_message = error_msg
                        session.commit()
                raise Exception(error_msg)
            except Exception as e:
                error_msg = f"ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                logger.error(f"Video processing error: {error_msg}", exc_info=True)
                with Session(engine) as session:
                    course = session.get(Course, course_id)
                    if course:
                        course.status = CourseStatus.failed
                        course.error_message = error_msg
                        session.commit()
                raise Exception(error_msg)
        
        # ì˜¤ë””ì˜¤ ì²˜ë¦¬ (STT)
        if audio_path:
            try:
                # íŒŒì¼ ê²½ë¡œ í™•ì¸ ë° ì •ê·œí™”
                if not isinstance(audio_path, Path):
                    audio_path = Path(audio_path)
                
                # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                if not audio_path.is_absolute():
                    audio_path = audio_path.resolve()
                
                logger.info(f"ğŸ“ Audio file path: {audio_path}")
                logger.info(f"ğŸ“ Audio file exists: {audio_path.exists()}")
                
                if not audio_path.exists():
                    # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒëŒ€ ê²½ë¡œë¡œë„ ì‹œë„
                    from core.config import AppSettings
                    app_settings = AppSettings()
                    potential_path = app_settings.uploads_dir / instructor_id / course_id / audio_path.name
                    if potential_path.exists():
                        audio_path = potential_path.resolve()
                        logger.info(f"ğŸ“ Found audio file at alternative path: {audio_path}")
                    else:
                        error_msg = f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_path} (also tried: {potential_path})"
                        logger.error(f"âŒ {error_msg}")
                        raise FileNotFoundError(error_msg)
                
                logger.info(f"ğŸ¤ Starting STT for audio: {audio_path}")
                _update_progress(course_id, 10, "ì˜¤ë””ì˜¤ ìŒì„± ì¸ì‹(STT) ì‹œì‘ (ë¬´ë£Œ ë¡œì»¬ Whisper ì‚¬ìš©)")
                
                # ë¡œì»¬ Whisper ì‚¬ìš© (ë¬´ë£Œ, API í‚¤ ë¶ˆí•„ìš”)
                logger.info(f"âœ… Using local Whisper (FREE, no API key needed)")
                
                # ì²« ì—…ë¡œë“œì´ë¯€ë¡œ ë¬´ì¡°ê±´ STT ì‹¤í–‰
                logger.info(f"ğŸ”„ Running STT (force_retranscribe=True to ensure fresh transcription)...")
                transcript_result = transcribe_video(
                    str(audio_path), 
                    settings=settings,
                    transcript_path=None,  # ê¸°ì¡´ íŒŒì¼ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ìƒì„±
                    force_retranscribe=True,  # ê°•ì œë¡œ STT ì‹¤í–‰
                    instructor_id=instructor_id,
                    course_id=course_id,
                )
                _update_progress(course_id, 40, "ì˜¤ë””ì˜¤ ìŒì„± ì¸ì‹(STT) ì™„ë£Œ")
                transcript_text = transcript_result.get("text", "")
                segments = transcript_result.get("segments", [])
                
                logger.info(f"ğŸ“ STT result - text length: {len(transcript_text)}, segments: {len(segments)}")
                
                # STT ì‹¤íŒ¨ ì²´í¬ - placeholderë‚˜ ì—ëŸ¬ ë©”ì‹œì§€ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ
                transcript_lower = transcript_text.lower()
                if ("placeholder" in transcript_lower or 
                    "transcription failed" in transcript_lower or
                    "failed:" in transcript_lower or
                    "error" in transcript_lower):
                    error_msg = (
                        f"âŒ STTê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. "
                        f"ë°˜í™˜ëœ ë©”ì‹œì§€: {transcript_text[:200]}... "
                        f"ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”."
                    )
                    logger.error(error_msg)
                    raise ValueError(error_msg)
                
                if not transcript_text or not transcript_text.strip():
                    error_msg = "STT ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”."
                    logger.error(f"âŒ {error_msg}")
                    raise ValueError(error_msg)
                
                logger.info(f"âœ… STT ì„±ê³µ! ì „ì‚¬ëœ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(transcript_text)} ë¬¸ì")
                
                # STT ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
                transcript_path = None
                if transcript_text:
                    try:
                        from core.config import AppSettings
                        import json
                        
                        app_settings = AppSettings()
                        course_dir = app_settings.uploads_dir / instructor_id / course_id
                        course_dir.mkdir(parents=True, exist_ok=True)
                        
                        # transcript íŒŒì¼ëª…: transcript_{ì›ë³¸íŒŒì¼ëª…}.json
                        transcript_filename = f"transcript_{audio_path.stem}.json"
                        transcript_file_path = course_dir / transcript_filename
                        
                        # JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥ (ì „ì²´ í…ìŠ¤íŠ¸ + ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´)
                        transcript_data = {
                            "text": transcript_text,
                            "segments": segments,
                            "source_file": audio_path.name,
                            "course_id": course_id,
                            "instructor_id": instructor_id,
                        }
                        
                        logger.info(f"Attempting to save transcript to: {transcript_file_path}")
                        logger.info(f"Transcript text length: {len(transcript_text)}")
                        
                        with transcript_file_path.open("w", encoding="utf-8") as f:
                            json.dump(transcript_data, f, ensure_ascii=False, indent=2)
                        
                        # íŒŒì¼ì´ ì‹¤ì œë¡œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
                        if transcript_file_path.exists():
                            file_size = transcript_file_path.stat().st_size
                            transcript_path = str(transcript_file_path)
                            logger.info(f"âœ… STT transcript JSON saved successfully: {transcript_path} (size: {file_size} bytes)")
                        else:
                            logger.error(f"âŒ Transcript file was not created: {transcript_file_path}")
                    except Exception as e:
                        import traceback
                        logger.error(f"âŒ Failed to save transcript file: {e}")
                        logger.error(f"Error details: {traceback.format_exc()}")
                        # íŒŒì¼ ì €ì¥ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                
                if transcript_text:
                    # ì „ì²´ í…ìŠ¤íŠ¸ ì €ì¥
                    texts.append(transcript_text)
                    
                    # ì„¸ê·¸ë¨¼íŠ¸ë³„ë¡œ ì„ë² ë”© ë° ë²¡í„° DB ì €ì¥ (íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨)
                    logger.info(f"Processing {len(segments)} audio segments for embedding")
                    segment_texts = []
                    segment_metas = []
                    for idx, seg in enumerate(segments):
                        seg_text = seg.get("text", "")
                        if not seg_text:
                            continue
                        seg_meta = {
                            "course_id": course_id,
                            "instructor_id": instructor_id,
                            "source": audio_path.name,
                            "start_time": seg.get("start"),
                            "end_time": seg.get("end"),
                            "segment_index": idx,
                            "type": "segment",
                        }
                        segment_texts.append(seg_text)
                        segment_metas.append(seg_meta)
                    
                    # ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ í•œ ë²ˆì— ì €ì¥ (ê³ ìœ  ID ë³´ì¥)
                    if segment_texts:
                        from ai.services.embeddings import embed_texts
                        from ai.services.vectorstore import get_chroma_client, get_collection
                        
                        _update_progress(course_id, 50, "ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘")
                        embeddings = embed_texts(segment_texts, settings)
                        client = get_chroma_client(settings)
                        collection = get_collection(client, settings)
                        
                        # ê³ ìœ  ID ìƒì„±: course_id-audio-segment-{index}
                        segment_ids = [f"{course_id}-audio-segment-{i}" for i in range(len(segment_texts))]
                        
                        collection.upsert(
                            ids=segment_ids,
                            documents=segment_texts,
                            metadatas=segment_metas,
                            embeddings=embeddings,
                        )
                        _update_progress(course_id, 60, "ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì„ë² ë”© ì™„ë£Œ")
                        logger.info(f"Stored {len(segment_texts)} audio segments to vector DB")
                
                # Audio ë ˆì½”ë“œ ìƒì„± (ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜)
                absolute_audio_path = audio_path.resolve()
                audio_file = Video(
                    course_id=course_id,
                    filename=audio_path.name,
                    storage_path=str(absolute_audio_path),
                    filetype="audio",
                    transcript_path=transcript_path,  # STT ê²°ê³¼ íŒŒì¼ ê²½ë¡œ ì €ì¥
                )
                session.add(audio_file)
                session.commit()
                logger.info(f"Audio record created: {audio_path.name}, transcript_path: {transcript_path}")
                
            except Exception as e:
                logger.error(f"Audio processing error: {e}", exc_info=True)
                course.status = CourseStatus.failed
                session.commit()
                return
        
        # PDF ì²˜ë¦¬ (í˜„ì¬ëŠ” í”Œë ˆì´ìŠ¤í™€ë”)
        if pdf_path:
            try:
                logger.info(f"Processing PDF: {pdf_path}")
                # TODO: PDF ì²˜ë¦¬ ë¡œì§ ì¶”ê°€ (ë°±ì—”ë“œ Aì—ì„œ êµ¬í˜„ ì˜ˆì •)
                pdf_text = f"PDF placeholder for {pdf_path.name}"
                texts.append(pdf_text)
                
                # PDF ë ˆì½”ë“œ ìƒì„± (ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜)
                absolute_pdf_path = pdf_path.resolve()
                doc = Video(
                    course_id=course_id,
                    filename=pdf_path.name,
                    storage_path=str(absolute_pdf_path),
                    filetype="pdf",
                )
                session.add(doc)
                session.commit()
                logger.info(f"PDF record created: {pdf_path.name}")
            except Exception as e:
                logger.error(f"PDF processing error: {e}", exc_info=True)
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ì„ë² ë”© ë° ë²¡í„° DB ì €ì¥ (ì„¸ê·¸ë¨¼íŠ¸ëŠ” ì´ë¯¸ ì €ì¥ë¨)
        logger.info(f"ğŸ“Š Total texts collected: {len(texts)}")
        if texts:
            try:
                from ai.services.embeddings import embed_texts
                from ai.services.vectorstore import get_chroma_client, get_collection
                
                # ì „ì²´ í…ìŠ¤íŠ¸ë„ ì €ì¥ (ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒ)
                logger.info("Ingesting full texts to vector DB")
                full_text = "\n\n".join(texts)
                
                if not full_text or len(full_text.strip()) == 0:
                    raise ValueError("ì „ì‚¬ëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. STT ì²˜ë¦¬ê°€ ì‹¤íŒ¨í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                
                # í…ìŠ¤íŠ¸ë¥¼ í† í° ê¸¸ì´ ê¸°ì¤€ìœ¼ë¡œ ì²­í¬ë¡œ ë¶„í• 
                _update_progress(course_id, 70, "ì „ì²´ í…ìŠ¤íŠ¸ ì„ë² ë”© ì¤€ë¹„ ì¤‘")
                text_chunks = _split_text_into_chunks(full_text, settings.embedding_model, max_tokens=7000)
                
                client = get_chroma_client(settings)
                collection = get_collection(client, settings)
                
                # ê° ì²­í¬ì— ëŒ€í•´ ì„ë² ë”© ìƒì„± ë° ì €ì¥
                if len(text_chunks) == 1:
                    # ì²­í¬ê°€ í•˜ë‚˜ë©´ ê¸°ì¡´ ë°©ì‹ê³¼ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
                    embeddings = embed_texts([full_text], settings)
                    collection.upsert(
                        ids=[f"{course_id}-full"],
                        documents=[full_text],
                        metadatas=[{
                            "course_id": course_id,
                            "instructor_id": instructor_id,
                            "type": "full_text",
                        }],
                        embeddings=embeddings,
                    )
                else:
                    # ì—¬ëŸ¬ ì²­í¬ì¸ ê²½ìš° ê°ê° ì„ë² ë”© ìƒì„±
                    embeddings = embed_texts(text_chunks, settings)
                    chunk_ids = [f"{course_id}-full-{i}" for i in range(len(text_chunks))]
                    chunk_metadatas = [{
                        "course_id": course_id,
                        "instructor_id": instructor_id,
                        "type": "full_text",
                        "chunk_index": i,
                        "total_chunks": len(text_chunks),
                    } for i in range(len(text_chunks))]
                    
                    collection.upsert(
                        ids=chunk_ids,
                        documents=text_chunks,
                        metadatas=chunk_metadatas,
                        embeddings=embeddings,
                    )
                
                _update_progress(course_id, 80, "ì „ì²´ í…ìŠ¤íŠ¸ ì„ë² ë”© ì™„ë£Œ")
                logger.info(f"Full text stored to vector DB ({len(text_chunks)} chunk(s))")
                
                # í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ì €ì¥
                # âš ï¸ ê°•ì‚¬ ì •ë³´ëŠ” ChromaDBì— ì €ì¥í•˜ì§€ ì•ŠìŒ (DBì—ì„œ ë™ì ìœ¼ë¡œ ë¡œë“œ)
                logger.info("Generating persona prompt")
                _update_progress(course_id, 85, "í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘")
                persona_prompt = pipeline.generate_persona_prompt(
                    course_id=course_id, 
                    sample_texts=texts,
                    instructor_info=None,  # ChromaDBì— ì €ì¥í•˜ì§€ ì•ŠìŒ
                    include_instructor_info=False  # ê°•ì‚¬ ì •ë³´ëŠ” DBì—ì„œ ë™ì ìœ¼ë¡œ ë¡œë“œ
                )
                
                persona_embeddings = embed_texts([persona_prompt], settings)
                collection.upsert(
                    ids=[f"{course_id}-persona"],
                    documents=[persona_prompt],
                    metadatas=[{
                        "course_id": course_id,
                        "instructor_id": instructor_id,
                        "type": "persona",
                    }],
                    embeddings=persona_embeddings,
                )
                _update_progress(course_id, 95, "í˜ë¥´ì†Œë‚˜ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")
                logger.info("Persona prompt generated and stored")
            except ValueError as e:
                error_msg = str(e)
                logger.error(f"Vector DB ingestion error: {error_msg}", exc_info=True)
                with Session(engine) as session:
                    course = session.get(Course, course_id)
                    if course:
                        course.status = CourseStatus.failed
                        course.error_message = error_msg
                        session.commit()
                raise Exception(error_msg)
            except Exception as e:
                error_msg = f"ë²¡í„° DB ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                logger.error(f"Vector DB ingestion error: {error_msg}", exc_info=True)
                with Session(engine) as session:
                    course = session.get(Course, course_id)
                    if course:
                        course.status = CourseStatus.failed
                        course.progress = 0
                        course.error_message = error_msg
                        session.commit()
                raise Exception(error_msg)
        else:
            logger.warning(f"âš ï¸ No texts to embed. STT may have failed or returned empty text.")
        
        # ì²˜ë¦¬ ì™„ë£Œ (textsê°€ ì—†ì–´ë„ STTê°€ ì™„ë£Œë˜ì—ˆìœ¼ë©´ ì™„ë£Œë¡œ í‘œì‹œ)
        with Session(engine) as session:
            course = session.get(Course, course_id)
            if course:
                course.status = CourseStatus.completed
                course.progress = 100
                course.error_message = None
                course.updated_at = datetime.utcnow()
                session.commit()
                logger.info(f"âœ… Course {course_id} processing completed successfully (progress: 100%)")
    except FileNotFoundError as e:
        error_msg = f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}"
        logger.error(f"âŒ {error_msg}", exc_info=True)
        with Session(engine) as session:
            course = session.get(Course, course_id)
            if course:
                course.status = CourseStatus.failed
                course.error_message = error_msg
                session.commit()
    except ValueError as e:
        error_msg = f"ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}"
        logger.error(f"âŒ {error_msg}", exc_info=True)
        with Session(engine) as session:
            course = session.get(Course, course_id)
            if course:
                course.status = CourseStatus.failed
                course.error_message = error_msg
                session.commit()
    except Exception as e:
        error_msg = f"ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        logger.error(f"âŒ {error_msg}", exc_info=True)
        import traceback
        logger.error(f"Full traceback:\n{traceback.format_exc()}")
        with Session(engine) as session:
            course = session.get(Course, course_id)
            if course:
                course.status = CourseStatus.failed
                course.error_message = error_msg
                session.commit()

